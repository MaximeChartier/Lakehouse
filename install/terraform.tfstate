{
  "version": 4,
  "terraform_version": "1.0.11",
  "serial": 134,
  "lineage": "a2c64961-1ed4-556e-b8ed-4edf62be2400",
  "outputs": {},
  "resources": [
    {
      "module": "module.istio_install",
      "mode": "managed",
      "type": "helm_release",
      "name": "istio_base",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "base",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "istio-base",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.12.0",
                "chart": "base",
                "name": "istio-base",
                "namespace": "istio-system",
                "revision": 1,
                "values": "null",
                "version": "1.12.0"
              }
            ],
            "name": "istio-base",
            "namespace": "istio-system",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://istio-release.storage.googleapis.com/charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 120,
            "values": null,
            "verify": false,
            "version": "1.12.0",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "module.kube.kubernetes_namespace.keycloak",
            "module.kube.kubernetes_namespace.ldap",
            "module.kube.kubernetes_namespace.mariadb",
            "module.kube.kubernetes_namespace.mlflow",
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub"
          ]
        }
      ]
    },
    {
      "module": "module.istio_install",
      "mode": "managed",
      "type": "helm_release",
      "name": "istio_ingress",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "gateway",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "istio-gateway",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.12.0",
                "chart": "gateway",
                "name": "istio-gateway",
                "namespace": "istio-system",
                "revision": 1,
                "values": "{\"labels\":{\"app\":\"istio-ingressgateway\",\"istio\":\"ingressgateway\"},\"name\":\"istio-ingressgateway\"}",
                "version": "1.12.0"
              }
            ],
            "name": "istio-gateway",
            "namespace": "istio-system",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://istio-release.storage.googleapis.com/charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [
              {
                "name": "labels.app",
                "type": "",
                "value": "istio-ingressgateway"
              },
              {
                "name": "labels.istio",
                "type": "",
                "value": "ingressgateway"
              },
              {
                "name": "name",
                "type": "",
                "value": "istio-ingressgateway"
              }
            ],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 120,
            "values": null,
            "verify": false,
            "version": "1.12.0",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub",
            "module.kube.kubernetes_namespace.keycloak",
            "module.kube.kubernetes_namespace.ldap",
            "module.kube.kubernetes_namespace.mariadb",
            "module.kube.kubernetes_namespace.mlflow",
            "module.istio_install.helm_release.istio_base",
            "module.istio_install.helm_release.istio_istiod"
          ]
        }
      ]
    },
    {
      "module": "module.istio_install",
      "mode": "managed",
      "type": "helm_release",
      "name": "istio_istiod",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "istiod",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "istio-istiod",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.12.0",
                "chart": "istiod",
                "name": "istio-istiod",
                "namespace": "istio-system",
                "revision": 1,
                "values": "{\"pilot\":{\"resources\":{\"requests\":{\"memory\":\"1024Mi\"}}}}",
                "version": "1.12.0"
              }
            ],
            "name": "istio-istiod",
            "namespace": "istio-system",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://istio-release.storage.googleapis.com/charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [
              {
                "name": "pilot.resources.requests.memory",
                "type": "",
                "value": "1024Mi"
              }
            ],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 120,
            "values": null,
            "verify": false,
            "version": "1.12.0",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "module.istio_install.helm_release.istio_base",
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub",
            "module.kube.kubernetes_namespace.keycloak",
            "module.kube.kubernetes_namespace.ldap",
            "module.kube.kubernetes_namespace.mariadb",
            "module.kube.kubernetes_namespace.mlflow"
          ]
        }
      ]
    },
    {
      "module": "module.jupyterhub_install",
      "mode": "managed",
      "type": "helm_release",
      "name": "jupyterhub",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "jupyterhub",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "jupyterhub",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.5.0",
                "chart": "jupyterhub",
                "name": "jupyterhub",
                "namespace": "jupyterhub",
                "revision": 1,
                "values": "{\"auxiliaryImage\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/bitnami-shell\",\"tag\":\"10-debian-10-r285\"},\"commonAnnotations\":{},\"commonLabels\":{},\"externalDatabase\":{\"database\":\"jupyterhub\",\"existingSecret\":\"\",\"host\":\"\",\"password\":\"\",\"port\":5432,\"user\":\"postgres\"},\"extraDeploy\":[],\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"storageClass\":\"\"},\"hub\":{\"adminUser\":\"user\",\"affinity\":{},\"args\":[],\"baseUrl\":\"/\",\"command\":[],\"configuration\":\"Chart:\\n  Name: {{ .Chart.Name }}\\n  Version: {{ .Chart.Version }}\\nRelease:\\n  Name: {{ .Release.Name }}\\n  Namespace: {{ .Release.Namespace }}\\n  Service: {{ .Release.Service }}\\nhub:\\n  config:\\n    JupyterHub:\\n      admin_access: true\\n      authenticator_class: dummy\\n      cookie_secret_file: /tmp/jupyterhub_cookie_secret\\n      DummyAuthenticator:\\n      {{- if .Values.hub.password }}\\n        password: {{ .Values.hub.password | quote }}\\n      {{- else }}\\n        password: {{ randAlphaNum 10 | quote }}\\n      {{- end }}\\n      Authenticator:\\n        admin_users:\\n          - {{ .Values.hub.adminUser }}\\n  cookieSecret:\\n  concurrentSpawnLimit: 64\\n  consecutiveFailureLimit: 5\\n  activeServerLimit:\\n  db:\\n    type: postgres\\n    url: postgresql://{{ ternary .Values.postgresql.postgresqlUsername .Values.externalDatabase.user .Values.postgresql.enabled }}@{{ ternary (include \\\"jupyterhub.postgresql.fullname\\\" .) .Values.externalDatabase.host .Values.postgresql.enabled }}:{{ ternary \\\"5432\\\" .Values.externalDatabase.port .Values.postgresql.enabled }}/{{ ternary .Values.postgresql.postgresqlDatabase .Values.externalDatabase.database .Values.postgresql.enabled }}\\n  services: {}\\n  allowNamedServers: false\\n  namedServerLimitPerUser:\\n  {{- if .Values.hub.metrics.serviceMonitor.enabled }}\\n  authenticatePrometheus: {{ .Values.hub.metrics.authenticatePrometheus }}\\n  {{- end }}\\n  redirectToServer:\\n  shutdownOnLogout:\\nsingleuser:\\n  podNameTemplate: {{ include \\\"common.names.fullname\\\" . }}-jupyter-{username}\\n  {{- if .Values.singleuser.tolerations }}\\n  extraTolerations: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.tolerations \\\"context\\\" $) | nindent 4 }}\\n  {{- end }}\\n  {{- if .Values.singleuser.nodeSelector }}\\n  nodeSelector: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.nodeSelector \\\"context\\\" $) | nindent 4 }}\\n  {{- end }}\\n  networkTools:\\n    image:\\n      name: {{ include \\\"jupyterhub.hubconfiguration.imageEntry\\\" ( dict \\\"imageRoot\\\" .Values.auxiliaryImage \\\"global\\\" $) }}\\n      tag: {{ .Values.auxiliaryImage.tag }}\\n      pullPolicy: {{ .Values.auxiliaryImage.pullPolicy }}\\n      pullSecrets: {{- include \\\"jupyterhub.imagePullSecrets.list\\\" . | nindent 8 }}\\n  cloudMetadata:\\n    blockWithIptables: false\\n  events: true\\n  extraAnnotations:\\n    {{- if .Values.commonAnnotations }}\\n    {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.commonAnnotations \\\"context\\\" $ ) | nindent 4 }}\\n    {{- end }}\\n    {{- if .Values.singleuser.podAnnotations }}\\n    {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.podAnnotations \\\"context\\\" $ ) | nindent 4 }}\\n    {{- end }}\\n  extraLabels:\\n    hub.jupyter.org/network-access-hub: \\\"true\\\"\\n    app.kubernetes.io/component: singleuser\\n    {{- include \\\"common.labels.standard\\\" . | nindent 4 }}\\n    {{- if .Values.commonLabels }}\\n    {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.commonLabels \\\"context\\\" $ ) | nindent 4 }}\\n    {{- end }}\\n    {{- if .Values.singleuser.podLabels }}\\n    {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.commonLabels \\\"context\\\" $ ) | nindent 4 }}\\n    {{- end }}\\n  {{- if .Values.singleuser.extraEnvVars }}\\n  extraEnv: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.extraEnvVars \\\"context\\\" $ ) | nindent 4 }}\\n  {{- end }}\\n  {{- if .Values.singleuser.lifecycleHooks }}\\n  lifecycleHooks: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.lifecycleHooks \\\"context\\\" $ ) | nindent 4 }}\\n  {{- end }}\\n  {{- if .Values.singleuser.initContainers }}\\n  initContainers: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.initContainers \\\"context\\\" $ ) | nindent 4 }}\\n  {{- end }}\\n  {{- if .Values.singleuser.sidecars }}\\n  extraContainers: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.sidecars \\\"context\\\" $ ) | nindent 4 }}\\n  {{- end }}\\n  {{- if .Values.singleuser.containerSecurityContext.enabled }}\\n  uid: {{ .Values.singleuser.containerSecurityContext.runAsUser }}\\n  {{- end }}\\n  {{- if .Values.singleuser.podSecurityContext.enabled }}\\n  fsGid: {{ .Values.singleuser.podSecurityContext.fsGroup }}\\n  {{- end }}\\n  serviceAccountName: {{ template \\\"jupyterhub.singleuserServiceAccountName\\\" . }}\\n  storage:\\n    {{- if .Values.singleuser.persistence.enabled }}\\n    type: dynamic\\n    {{- else }}\\n    type: none\\n    {{- end }}\\n    extraLabels:\\n      app.kubernetes.io/component: singleuser\\n      {{- include \\\"common.labels.standard\\\" . | nindent 6 }}\\n    {{- if .Values.singleuser.extraVolumes }}\\n    extraVolumes: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.extraVolumes \\\"context\\\" $ ) | nindent 4 }}\\n    {{- end }}\\n    {{- if .Values.singleuser.extraVolumeMounts }}\\n    extraVolumeMounts: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.extraVolumeMounts \\\"context\\\" $ ) | nindent 4 }}\\n    {{- end }}\\n    capacity: {{ .Values.singleuser.persistence.size }}\\n    homeMountPath: {{ .Values.singleuser.notebookDir }}\\n    dynamic:\\n      {{ include \\\"jupyterhub.storage.class\\\" (dict \\\"persistence\\\" .Values.singleuser.persistence \\\"global\\\" .Values.global) }}\\n      pvcNameTemplate: {{ include \\\"common.names.fullname\\\" . }}-claim-{username}{servername}\\n      volumeNameTemplate: {{ include \\\"common.names.fullname\\\" . }}-volume-{username}{servername}\\n      storageAccessModes: {{- include \\\"common.tplvalues.render\\\" ( dict \\\"value\\\" .Values.singleuser.persistence.accessModes \\\"context\\\" $ ) | nindent 8 }}\\n  image:\\n    name: {{ include \\\"jupyterhub.hubconfiguration.imageEntry\\\" ( dict \\\"imageRoot\\\" .Values.singleuser.image \\\"global\\\" $) }}\\n    tag: {{ .Values.singleuser.image.tag }}\\n    pullPolicy: {{ .Values.singleuser.image.pullPolicy }}\\n    pullSecrets: {{- include \\\"jupyterhub.imagePullSecrets.list\\\" . | nindent 8 }}\\n  startTimeout: 300\\n  {{- /* We need to replace the Kubernetes memory/cpu terminology (e.g. 10Gi, 10Mi) with one compatible with Python (10G, 10M) */}}\\n  cpu:\\n    limit: {{ regexReplaceAll \\\"([A-Za-z])i\\\" (default \\\"\\\" .Values.singleuser.resources.limits.cpu)  \\\"${1}\\\"}}\\n    guarantee: {{ regexReplaceAll \\\"([A-Za-z])i\\\" (default \\\"\\\" .Values.singleuser.resources.requests.cpu) \\\"${1}\\\" }}\\n  memory:\\n    limit: {{ regexReplaceAll \\\"([A-Za-z])i\\\" (default \\\"\\\" .Values.singleuser.resources.limits.memory) \\\"${1}\\\" }}\\n    guarantee: {{ regexReplaceAll \\\"([A-Za-z])i\\\" (default \\\"\\\" .Values.singleuser.resources.requests.memory) \\\"${1}\\\" }}\\n  {{- if .Values.singleuser.command }}\\n  cmd: {{- include \\\"common.tplvalues.render\\\" (dict \\\"value\\\" .Values.singleuser.command \\\"context\\\" $) | nindent 12 }}\\n  {{- else }}\\n  cmd: jupyterhub-singleuser\\n  {{- end }}\\n  defaultUrl:\\ncull:\\n  enabled: true\\n  users: false\\n  removeNamedServers: false\\n  timeout: 3600\\n  every: 600\\n  concurrency: 10\\n  maxAge: 0\\n\",\"containerPort\":8081,\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1000},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"existingConfigmap\":\"\",\"existingSecret\":\"\",\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/jupyterhub\",\"tag\":\"1.5.0-debian-10-r39\"},\"initContainers\":[],\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":30,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":3},\"metrics\":{\"authenticatePrometheus\":false,\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"namespace\":\"\",\"path\":\"/hub/metrics\",\"relabellings\":[],\"scrapeTimeout\":\"\"}},\"networkPolicy\":{\"allowInterspaceAccess\":true,\"enabled\":true,\"extraEgress\":\"## Hub --\\u003e Any IP:PORT\\n##\\n- to:\\n\",\"extraIngress\":\"\"},\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"password\":\"\",\"pdb\":{\"create\":false,\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"rbac\":{\"create\":true},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":30,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":3},\"resources\":{\"limits\":{},\"requests\":{}},\"service\":{\"externalTrafficPolicy\":\"Cluster\",\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"http\":\"\"},\"port\":8081,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"create\":true,\"name\":\"\"},\"sidecars\":[],\"startupProbe\":{\"enabled\":true,\"failureThreshold\":30,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":3},\"tolerations\":[],\"updateStrategy\":{\"type\":\"RollingUpdate\"}},\"imagePuller\":{\"affinity\":{},\"args\":[],\"command\":[],\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"enabled\":true,\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"initContainers\":[],\"lifecycleHooks\":{},\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"resources\":{\"limits\":{},\"requests\":{}},\"sidecars\":[],\"tolerations\":[],\"updateStrategy\":{\"type\":\"RollingUpdate\"}},\"kubeVersion\":\"\",\"nameOverride\":\"\",\"postgresql\":{\"enabled\":true,\"existingSecret\":\"\",\"nameOverride\":\"\",\"persistence\":{\"accessMode\":\"ReadWriteOnce\",\"enabled\":true,\"existingClaim\":\"\",\"size\":\"8Gi\",\"storageClass\":\"\"},\"postgresqlDatabase\":\"bitnami_jupyterhub\",\"postgresqlPassword\":\"\",\"postgresqlUsername\":\"bn_jupyterhub\",\"service\":{\"port\":5432}},\"proxy\":{\"affinity\":{},\"args\":[],\"command\":[],\"containerPort\":{\"api\":8001,\"http\":8000,\"metrics\":8002},\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"debug\":false,\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/configurable-http-proxy\",\"tag\":\"4.5.0-debian-10-r150\"},\"ingress\":{\"annotations\":{},\"apiVersion\":\"\",\"enabled\":false,\"extraHosts\":[],\"extraPaths\":[],\"extraTls\":[],\"hostname\":\"jupyterhub.local\",\"ingressClassName\":\"\",\"path\":\"/\",\"pathType\":\"ImplementationSpecific\",\"secrets\":[],\"selfSigned\":false,\"tls\":false},\"initContainers\":[],\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":30,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":3},\"metrics\":{\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"namespace\":\"\",\"path\":\"/metrics\",\"relabellings\":[],\"scrapeTimeout\":\"\"}},\"networkPolicy\":{\"allowInterspaceAccess\":true,\"enabled\":true,\"extraEgress\":\"\",\"extraIngress\":\"## Any IP --\\u003e Proxy\\n##\\n- ports:\\n    - port: {{ .Values.proxy.containerPort.http }}\\n\"},\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"pdb\":{\"create\":false,\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":30,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":3},\"resources\":{\"limits\":{},\"requests\":{}},\"secretToken\":\"\",\"service\":{\"api\":{\"externalTrafficPolicy\":\"Cluster\",\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"http\":\"\"},\"port\":8001,\"type\":\"ClusterIP\"},\"metrics\":{\"externalTrafficPolicy\":\"Cluster\",\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"http\":\"\"},\"port\":8002,\"type\":\"ClusterIP\"},\"public\":{\"externalTrafficPolicy\":\"Cluster\",\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"http\":\"\"},\"port\":80,\"type\":\"ClusterIP\"}},\"sidecars\":[],\"startupProbe\":{\"enabled\":true,\"failureThreshold\":30,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":3},\"tolerations\":[],\"updateStrategy\":{\"type\":\"RollingUpdate\"}},\"singleuser\":{\"command\":[],\"containerPort\":8888,\"containerSecurityContext\":{\"enabled\":true,\"runAsUser\":1001},\"extraEnvVars\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/jupyter-base-notebook\",\"tag\":\"1.5.0-debian-10-r38\"},\"initContainers\":[],\"lifecycleHooks\":{},\"networkPolicy\":{\"allowCloudMetadataAccess\":false,\"allowInterspaceAccess\":true,\"enabled\":true,\"extraEgress\":\"\",\"extraIngress\":\"\"},\"nodeSelector\":{},\"notebookDir\":\"/opt/bitnami/jupyterhub-singleuser\",\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"enabled\":true,\"size\":\"10Gi\",\"storageClass\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"resources\":{\"limits\":{},\"requests\":{}},\"serviceAccount\":{\"create\":true,\"name\":\"\"},\"sidecars\":[],\"tolerations\":[]}}",
                "version": "0.3.6"
              }
            ],
            "name": "jupyterhub",
            "namespace": "jupyterhub",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://charts.bitnami.com/bitnami",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 1000,
            "values": [
              "## @section Global parameters\n## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass\n\n## @param global.imageRegistry Global Docker image registry\n## @param global.imagePullSecrets Global Docker registry secret names as an array\n## @param global.storageClass Global StorageClass for Persistent Volume(s)\n##\nglobal:\n  imageRegistry: \"\"\n  ## E.g.\n  ## imagePullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  imagePullSecrets: []\n  storageClass: \"\"\n\n## @section Common parameters\n\n## @param kubeVersion Override Kubernetes version\n##\nkubeVersion: \"\"\n## @param nameOverride String to partially override common.names.fullname (will maintain the release name)\n##\nnameOverride: \"\"\n## @param fullnameOverride String to fully override common.names.fullname\n##\nfullnameOverride: \"\"\n## @param commonLabels  Labels to add to all deployed objects\n##\ncommonLabels: {}\n## @param commonAnnotations  Annotations to add to all deployed objects\n##\ncommonAnnotations: {}\n## @param extraDeploy Array of extra objects to deploy with the release\n##\nextraDeploy: []\n\n## @section Hub deployment parameters\n\n## Hub deployment parameters\n##\nhub:\n  image:\n    ## @param hub.image.registry Hub image registry\n    ##\n    registry: docker.io\n    ## @param hub.image.repository Hub image repository\n    ##\n    repository: bitnami/jupyterhub\n    ## @param hub.image.tag Hub image tag (immutabe tags are recommended)\n    ##\n    tag: 1.5.0-debian-10-r39\n    ## Specify a imagePullPolicy\n    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n    ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n    ##\n    ## @param hub.image.pullPolicy Hub image pull policy\n    ##\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## e.g:\n    ## pullSecrets:\n    ##  - myRegistryKeySecretName\n    ## @param hub.image.pullSecrets Hub image pull secrets\n    ##\n    pullSecrets: []\n  ## Configure extra options for startup probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-startup-readiness-probes/#configure-probes\n  ## @param hub.startupProbe.enabled Enable startupProbe\n  ## @param hub.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param hub.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param hub.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param hub.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param hub.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    failureThreshold: 30\n    timeoutSeconds: 3\n    successThreshold: 1\n  ## Configure extra options for liveness and readiness probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param hub.livenessProbe.enabled Enable livenessProbe\n  ## @param hub.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param hub.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param hub.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param hub.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param hub.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    failureThreshold: 30\n    timeoutSeconds: 3\n    successThreshold: 1\n  ## @param hub.readinessProbe.enabled Enable readinessProbe\n  ## @param hub.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param hub.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param hub.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param hub.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param hub.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    failureThreshold: 30\n    timeoutSeconds: 3\n    successThreshold: 1\n  ## @param hub.baseUrl Hub base URL\n  ##\n  baseUrl: /\n  ## @param hub.adminUser Hub Dummy authenticator admin user\n  ##\n  adminUser: user\n  ## @param hub.password Hub Dummy authenticator password\n  ##\n  password: \"\"\n  ## Configuration file passed to the hub. This will be used by the jupyterhub_config.py file\n  ## This configuration uses the values for the `singleuser` section. In the upstream chart the\n  ## values.yaml file is mounted in the hub container. This is chart, we tried to separate both\n  ## configuration so we could follow the Bitnami value standards\n  ## @param hub.configuration [string] Hub configuration file (to be used by jupyterhub_config.py)\n  ##\n  configuration: |\n    Chart:\n      Name: {{ .Chart.Name }}\n      Version: {{ .Chart.Version }}\n    Release:\n      Name: {{ .Release.Name }}\n      Namespace: {{ .Release.Namespace }}\n      Service: {{ .Release.Service }}\n    hub:\n      config:\n        JupyterHub:\n          admin_access: true\n          authenticator_class: dummy\n          cookie_secret_file: /tmp/jupyterhub_cookie_secret\n          DummyAuthenticator:\n          {{- if .Values.hub.password }}\n            password: {{ .Values.hub.password | quote }}\n          {{- else }}\n            password: {{ randAlphaNum 10 | quote }}\n          {{- end }}\n          Authenticator:\n            admin_users:\n              - {{ .Values.hub.adminUser }}\n      cookieSecret:\n      concurrentSpawnLimit: 64\n      consecutiveFailureLimit: 5\n      activeServerLimit:\n      db:\n        type: postgres\n        url: postgresql://{{ ternary .Values.postgresql.postgresqlUsername .Values.externalDatabase.user .Values.postgresql.enabled }}@{{ ternary (include \"jupyterhub.postgresql.fullname\" .) .Values.externalDatabase.host .Values.postgresql.enabled }}:{{ ternary \"5432\" .Values.externalDatabase.port .Values.postgresql.enabled }}/{{ ternary .Values.postgresql.postgresqlDatabase .Values.externalDatabase.database .Values.postgresql.enabled }}\n      services: {}\n      allowNamedServers: false\n      namedServerLimitPerUser:\n      {{- if .Values.hub.metrics.serviceMonitor.enabled }}\n      authenticatePrometheus: {{ .Values.hub.metrics.authenticatePrometheus }}\n      {{- end }}\n      redirectToServer:\n      shutdownOnLogout:\n    singleuser:\n      podNameTemplate: {{ include \"common.names.fullname\" . }}-jupyter-{username}\n      {{- if .Values.singleuser.tolerations }}\n      extraTolerations: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.tolerations \"context\" $) | nindent 4 }}\n      {{- end }}\n      {{- if .Values.singleuser.nodeSelector }}\n      nodeSelector: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.nodeSelector \"context\" $) | nindent 4 }}\n      {{- end }}\n      networkTools:\n        image:\n          name: {{ include \"jupyterhub.hubconfiguration.imageEntry\" ( dict \"imageRoot\" .Values.auxiliaryImage \"global\" $) }}\n          tag: {{ .Values.auxiliaryImage.tag }}\n          pullPolicy: {{ .Values.auxiliaryImage.pullPolicy }}\n          pullSecrets: {{- include \"jupyterhub.imagePullSecrets.list\" . | nindent 8 }}\n      cloudMetadata:\n        blockWithIptables: false\n      events: true\n      extraAnnotations:\n        {{- if .Values.commonAnnotations }}\n        {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.commonAnnotations \"context\" $ ) | nindent 4 }}\n        {{- end }}\n        {{- if .Values.singleuser.podAnnotations }}\n        {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.podAnnotations \"context\" $ ) | nindent 4 }}\n        {{- end }}\n      extraLabels:\n        hub.jupyter.org/network-access-hub: \"true\"\n        app.kubernetes.io/component: singleuser\n        {{- include \"common.labels.standard\" . | nindent 4 }}\n        {{- if .Values.commonLabels }}\n        {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.commonLabels \"context\" $ ) | nindent 4 }}\n        {{- end }}\n        {{- if .Values.singleuser.podLabels }}\n        {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.commonLabels \"context\" $ ) | nindent 4 }}\n        {{- end }}\n      {{- if .Values.singleuser.extraEnvVars }}\n      extraEnv: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.extraEnvVars \"context\" $ ) | nindent 4 }}\n      {{- end }}\n      {{- if .Values.singleuser.lifecycleHooks }}\n      lifecycleHooks: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.lifecycleHooks \"context\" $ ) | nindent 4 }}\n      {{- end }}\n      {{- if .Values.singleuser.initContainers }}\n      initContainers: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.initContainers \"context\" $ ) | nindent 4 }}\n      {{- end }}\n      {{- if .Values.singleuser.sidecars }}\n      extraContainers: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.sidecars \"context\" $ ) | nindent 4 }}\n      {{- end }}\n      {{- if .Values.singleuser.containerSecurityContext.enabled }}\n      uid: {{ .Values.singleuser.containerSecurityContext.runAsUser }}\n      {{- end }}\n      {{- if .Values.singleuser.podSecurityContext.enabled }}\n      fsGid: {{ .Values.singleuser.podSecurityContext.fsGroup }}\n      {{- end }}\n      serviceAccountName: {{ template \"jupyterhub.singleuserServiceAccountName\" . }}\n      storage:\n        {{- if .Values.singleuser.persistence.enabled }}\n        type: dynamic\n        {{- else }}\n        type: none\n        {{- end }}\n        extraLabels:\n          app.kubernetes.io/component: singleuser\n          {{- include \"common.labels.standard\" . | nindent 6 }}\n        {{- if .Values.singleuser.extraVolumes }}\n        extraVolumes: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.extraVolumes \"context\" $ ) | nindent 4 }}\n        {{- end }}\n        {{- if .Values.singleuser.extraVolumeMounts }}\n        extraVolumeMounts: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.extraVolumeMounts \"context\" $ ) | nindent 4 }}\n        {{- end }}\n        capacity: {{ .Values.singleuser.persistence.size }}\n        homeMountPath: {{ .Values.singleuser.notebookDir }}\n        dynamic:\n          {{ include \"jupyterhub.storage.class\" (dict \"persistence\" .Values.singleuser.persistence \"global\" .Values.global) }}\n          pvcNameTemplate: {{ include \"common.names.fullname\" . }}-claim-{username}{servername}\n          volumeNameTemplate: {{ include \"common.names.fullname\" . }}-volume-{username}{servername}\n          storageAccessModes: {{- include \"common.tplvalues.render\" ( dict \"value\" .Values.singleuser.persistence.accessModes \"context\" $ ) | nindent 8 }}\n      image:\n        name: {{ include \"jupyterhub.hubconfiguration.imageEntry\" ( dict \"imageRoot\" .Values.singleuser.image \"global\" $) }}\n        tag: {{ .Values.singleuser.image.tag }}\n        pullPolicy: {{ .Values.singleuser.image.pullPolicy }}\n        pullSecrets: {{- include \"jupyterhub.imagePullSecrets.list\" . | nindent 8 }}\n      startTimeout: 300\n      {{- /* We need to replace the Kubernetes memory/cpu terminology (e.g. 10Gi, 10Mi) with one compatible with Python (10G, 10M) */}}\n      cpu:\n        limit: {{ regexReplaceAll \"([A-Za-z])i\" (default \"\" .Values.singleuser.resources.limits.cpu)  \"${1}\"}}\n        guarantee: {{ regexReplaceAll \"([A-Za-z])i\" (default \"\" .Values.singleuser.resources.requests.cpu) \"${1}\" }}\n      memory:\n        limit: {{ regexReplaceAll \"([A-Za-z])i\" (default \"\" .Values.singleuser.resources.limits.memory) \"${1}\" }}\n        guarantee: {{ regexReplaceAll \"([A-Za-z])i\" (default \"\" .Values.singleuser.resources.requests.memory) \"${1}\" }}\n      {{- if .Values.singleuser.command }}\n      cmd: {{- include \"common.tplvalues.render\" (dict \"value\" .Values.singleuser.command \"context\" $) | nindent 12 }}\n      {{- else }}\n      cmd: jupyterhub-singleuser\n      {{- end }}\n      defaultUrl:\n    cull:\n      enabled: true\n      users: false\n      removeNamedServers: false\n      timeout: 3600\n      every: 600\n      concurrency: 10\n      maxAge: 0\n  ## @param hub.containerPort Hub container port\n  ##\n  containerPort: 8081\n  ## @param hub.existingConfigmap Configmap with Hub init scripts (replaces the scripts in templates/hub/configmap.yml)\n  ##\n  existingConfigmap: \"\"\n  ## @param hub.existingSecret Secret with hub configuration (replaces the hub.configuration value) and proxy token\n  ##\n  existingSecret: \"\"\n  ## @param hub.command Override Hub default command\n  ##\n  command: []\n  ## @param hub.args Override Hub default args\n  ##\n  args: []\n  pdb:\n    ## @param hub.pdb.create Deploy Hub PodDisruptionBudget\n    ##\n    create: false\n    ## @param hub.pdb.minAvailable Set minimum available hub instances\n    ##\n    minAvailable: \"\"\n    ## @param hub.pdb.maxUnavailable Set maximum available hub instances\n    ##\n    maxUnavailable: \"\"\n  ## @param hub.priorityClassName Hub pod priority class name\n  ##\n  priorityClassName: \"\"\n  ## @param hub.hostAliases Add deployment host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## hub resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param hub.resources.limits The resources limits for the container\n  ## @param hub.resources.requests The requested resources for the container\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##   cpu: 200m\n    ##   memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##   cpu: 200m\n    ##   memory: 10Mi\n    requests: {}\n  ## hub containers' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param hub.containerSecurityContext.enabled Enabled Hub containers' Security Context\n  ## @param hub.containerSecurityContext.runAsUser Set Hub container's Security Context runAsUser\n  ## @param hub.containerSecurityContext.runAsNonRoot Set Hub container's Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1000\n    runAsNonRoot: true\n  ## hub pods' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param hub.podSecurityContext.enabled Enabled Hub pods' Security Context\n  ## @param hub.podSecurityContext.fsGroup Set Hub pod's Security Context fsGroup\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## Pod affinity preset\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ## Allowed values: soft, hard\n  ## @param hub.podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ##\n  podAffinityPreset: \"\"\n  ## Pod anti-affinity preset\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ## @param hub.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ##\n  podAntiAffinityPreset: soft\n  ## Node affinity preset\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ## @param hub.nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ## @param hub.nodeAffinityPreset.key Node label key to match. Ignored if `affinity` is set\n  ## @param hub.nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set\n  ##\n  nodeAffinityPreset:\n    type: \"\"\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param hub.affinity  Affinity for pod assignment.\n  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ##\n  affinity: {}\n  ## @param hub.nodeSelector Node labels for pod assignment.\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param hub.tolerations Tolerations for pod assignment.\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param hub.podLabels Pod extra labels\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n  ##\n  podLabels: {}\n  ## @param hub.podAnnotations Annotations for server pods.\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param hub.lifecycleHooks LifecycleHooks for the hub container to automate configuration before or after startup\n  ##\n  lifecycleHooks: {}\n  ## @param hub.customStartupProbe Override default startup probe\n  ##\n  customStartupProbe: {}\n  ## @param hub.customLivenessProbe Override default liveness probe\n  ##\n  customLivenessProbe: {}\n  ## @param hub.customReadinessProbe Override default readiness probe\n  ##\n  customReadinessProbe: {}\n  ## @param hub.updateStrategy.type Update strategy - only really applicable for deployments with RWO PVs attached\n  ## If replicas = 1, an update can get \"stuck\", as the previous pod remains attached to the\n  ## PV, and the \"incoming\" pod can never start. Changing the strategy to \"Recreate\" will\n  ## terminate the single previous pod, so that the new, incoming pod can attach to the PV\n  ##\n  updateStrategy:\n    type: RollingUpdate\n  ## @param hub.extraEnvVars Add extra environment variables to the Hub container\n  ## Example:\n  ## extraEnvVars:\n  ##   - name: FOO\n  ##     value: \"bar\"\n  ##\n  extraEnvVars: []\n  ## @param hub.extraEnvVarsCM Name of existing ConfigMap containing extra env vars\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param hub.extraEnvVarsSecret Name of existing Secret containing extra env vars\n  ##\n  extraEnvVarsSecret: \"\"\n  ## @param hub.extraVolumes Optionally specify extra list of additional volumes for Hub pods\n  ##\n  extraVolumes: []\n  ## @param hub.extraVolumeMounts Optionally specify extra list of additional volumeMounts for Hub container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param hub.initContainers Add additional init containers to the Hub pods\n  ## Example:\n  ## initContainers:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  initContainers: []\n  ## @param hub.sidecars Add additional sidecar containers to the Hub pod\n  ## Example:\n  ## sidecars:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  sidecars: []\n\n  ## @section Hub RBAC parameters\n\n  ## ServiceAccount parameters\n  ##\n  serviceAccount:\n    ## @param hub.serviceAccount.create Specifies whether a ServiceAccount should be created\n    ##\n    create: true\n    ## @param hub.serviceAccount.name Override Hub service account name\n    ## If not set and create is true, a name is generated using the fullname template\n    ##\n    name: \"\"\n  ## RBAC resources\n  ##\n  rbac:\n    ## @param hub.rbac.create Specifies whether RBAC resources should be created\n    ##\n    create: true\n\n  ## @section Hub Traffic Exposure Parameters\n\n  ## Network policy\n  ##\n  networkPolicy:\n    ## @param hub.networkPolicy.enabled Deploy Hub network policies\n    ##\n    enabled: true\n    ## @param hub.networkPolicy.allowInterspaceAccess Allow communication between pods in different namespaces\n    ##\n    allowInterspaceAccess: true\n    ## @param hub.networkPolicy.extraIngress Add extra ingress rules to the NetworkPolicy\n    ##\n    extraIngress: \"\"\n    ## @param hub.networkPolicy.extraEgress [string] Add extra ingress rules to the NetworkPolicy\n    ##\n    extraEgress: |\n      ## Hub --\u003e Any IP:PORT\n      ##\n      - to:\n  service:\n    ## @param hub.service.type Hub service type\n    ##\n    type: ClusterIP\n    ## @param hub.service.port Hub service HTTP port\n    port: 8081\n    ## @param hub.service.loadBalancerIP Hub service LoadBalancer IP (optional, cloud specific)\n    ## ref: https://kubernetes.io/docs/user-guide/services/#type-loadbalancer\n    ##\n    loadBalancerIP: \"\"\n    ## @param hub.service.loadBalancerSourceRanges loadBalancerIP source ranges for the Service\n    ##\n    loadBalancerSourceRanges: []\n    ## @param hub.service.nodePorts.http NodePort for the HTTP endpoint\n    ## nodePorts:\n    ##   http: \u003cto set explicitly, choose port between 30000-32767\u003e\n    ##   https: \u003cto set explicitly, choose port between 30000-32767\u003e\n    ##\n    nodePorts:\n      http: \"\"\n    ## @param hub.service.externalTrafficPolicy External traffic policy for the service\n    ## Enable client source IP preservation\n    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n    ##\n    externalTrafficPolicy: Cluster\n\n  ## @section Hub Metrics parameters\n\n  metrics:\n    ## @param hub.metrics.authenticatePrometheus Use authentication for Prometheus\n    ## To allow public access without authentication for prometheus metrics set environment as follows.\n    ##\n    authenticatePrometheus: false\n    ## Prometheus Operator ServiceMonitor configuration\n    ##\n    serviceMonitor:\n      ## @param hub.metrics.serviceMonitor.enabled If the operator is installed in your cluster, set to true to create a Service Monitor Entry\n      ##\n      enabled: false\n      ## @param hub.metrics.serviceMonitor.namespace Namespace which Prometheus is running in\n      ##\n      namespace: \"\"\n      ## @param hub.metrics.serviceMonitor.path HTTP path to scrape for metrics\n      ##\n      path: /hub/metrics\n      ## @param hub.metrics.serviceMonitor.interval Interval at which metrics should be scraped\n      ##\n      interval: 30s\n      ## @param hub.metrics.serviceMonitor.scrapeTimeout Specify the timeout after which the scrape is ended\n      ## e.g:\n      ## scrapeTimeout: 30s\n      scrapeTimeout: \"\"\n      ## @param hub.metrics.serviceMonitor.relabellings Specify Metric Relabellings to add to the scrape endpoint\n      ##\n      relabellings: []\n      ## @param hub.metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint\n      ##\n      honorLabels: false\n      ## @param hub.metrics.serviceMonitor.additionalLabels Used to pass Labels that are required by the installed Prometheus Operator\n      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec\n      ##\n      additionalLabels: {}\n\n## @section Proxy deployment parameters\n\n## Proxy deployment parameters\n##\nproxy:\n  ## @param proxy.image.registry Proxy image registry\n  ## @param proxy.image.repository Proxy image repository\n  ## @param proxy.image.tag Proxy image tag (immutable tags are recommended)\n  ## @param proxy.image.pullPolicy Proxy image pull policy\n  ## @param proxy.image.pullSecrets Proxy image pull secrets\n  ## @param proxy.image.debug Activate verbose output\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/configurable-http-proxy\n    tag: 4.5.0-debian-10-r150\n    ## Specify a imagePullPolicy\n    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n    ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n    ##\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## e.g:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n    ## Enable debug mode\n    ##\n    debug: false\n  ## Configure extra options for startup probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-startup-readiness-probes/#configure-probes\n  ## @param proxy.startupProbe.enabled Enable startupProbe\n  ## @param proxy.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param proxy.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param proxy.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param proxy.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param proxy.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    failureThreshold: 30\n    timeoutSeconds: 3\n    successThreshold: 1\n  ## Configure extra options for liveness and readiness probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param proxy.livenessProbe.enabled Enable livenessProbe\n  ## @param proxy.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param proxy.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param proxy.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param proxy.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param proxy.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    failureThreshold: 30\n    timeoutSeconds: 3\n    successThreshold: 1\n  ## @param proxy.readinessProbe.enabled Enable readinessProbe\n  ## @param proxy.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param proxy.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param proxy.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param proxy.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param proxy.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    failureThreshold: 30\n    timeoutSeconds: 3\n    successThreshold: 1\n  ## @param proxy.command Override Proxy default command\n  ##\n  command: []\n  ## @param proxy.args Override Proxy default args\n  ##\n  args: []\n  ## @param proxy.secretToken Proxy secret token (used for communication with the Hub)\n  ##\n  secretToken: \"\"\n  ## Deployment pod host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ## @param proxy.hostAliases Add deployment host aliases\n  ##\n  hostAliases: []\n  ## PodDisruptionBudget settings\n  ##\n  pdb:\n    ## @param proxy.pdb.create Deploy Proxy PodDisruptionBudget\n    ##\n    create: false\n    ## @param proxy.pdb.minAvailable Set minimum available proxy instances\n    ##\n    minAvailable: \"\"\n    ## @param proxy.pdb.maxUnavailable Set maximum available proxy instances\n    ##\n    maxUnavailable: \"\"\n  ## Container ports\n  ##\n  containerPort:\n    ## @param proxy.containerPort.api Proxy api container port\n    ##\n    api: 8001\n    ## @param proxy.containerPort.metrics Proxy metrics container port\n    ##\n    metrics: 8002\n    ## @param proxy.containerPort.http Proxy http container port\n    ##\n    http: 8000\n  ## @param proxy.priorityClassName Proxy pod priority class name\n  ##\n  priorityClassName: \"\"\n  ## proxy resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param proxy.resources.limits The resources limits for the container\n  ## @param proxy.resources.requests The requested resources for the container\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##   cpu: 200m\n    ##   memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##   cpu: 200m\n    ##   memory: 10Mi\n    requests: {}\n  ## proxy containers' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param proxy.containerSecurityContext.enabled Enabled Proxy containers' Security Context\n  ## @param proxy.containerSecurityContext.runAsUser Set Proxy container's Security Context runAsUser\n  ## @param proxy.containerSecurityContext.runAsNonRoot Set Proxy container's Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## Proxy pods' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param proxy.podSecurityContext.enabled Enabled Proxy pods' Security Context\n  ## @param proxy.podSecurityContext.fsGroup Set Proxy pod's Security Context fsGroup\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## @param proxy.podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAffinityPreset: \"\"\n  ## @param proxy.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAntiAffinityPreset: soft\n  ## Node affinity preset\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ## Allowed values: soft, hard\n  ## @param proxy.nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ## @param proxy.nodeAffinityPreset.key Node label key to match. Ignored if `affinity` is set\n  ## @param proxy.nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set\n  ##\n  nodeAffinityPreset:\n    type: \"\"\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param proxy.affinity Affinity for pod assignment. Evaluated as a template.\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ##\n  affinity: {}\n  ## @param proxy.nodeSelector Node labels for pod assignment. Evaluated as a template.\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param proxy.tolerations Tolerations for pod assignment. Evaluated as a template.\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param proxy.podLabels Extra labels for Proxy pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n  ##\n  podLabels: {}\n  ## @param proxy.podAnnotations Annotations for Proxy pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param proxy.lifecycleHooks Add lifecycle hooks to the Proxy deployment\n  ##\n  lifecycleHooks: {}\n  ## @param proxy.customStartupProbe Override default startup probe\n  ##\n  customStartupProbe: {}\n  ## @param proxy.customLivenessProbe Override default liveness probe\n  ##\n  customLivenessProbe: {}\n  ## @param proxy.customReadinessProbe Override default readiness probe\n  ##\n  customReadinessProbe: {}\n  ## @param proxy.updateStrategy.type Update strategy - only really applicable for deployments with RWO PVs attached\n  ## If replicas = 1, an update can get \"stuck\", as the previous pod remains attached to the\n  ## PV, and the \"incoming\" pod can never start. Changing the strategy to \"Recreate\" will\n  ## terminate the single previous pod, so that the new, incoming pod can attach to the PV\n  ##\n  updateStrategy:\n    type: RollingUpdate\n  ## @param proxy.extraEnvVars Add extra environment variables to the Proxy container\n  ## Example:\n  ## extraEnvVars:\n  ##   - name: FOO\n  ##     value: \"bar\"\n  ##\n  extraEnvVars: []\n  ## @param proxy.extraEnvVarsCM Name of existing ConfigMap containing extra env vars\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param proxy.extraEnvVarsSecret Name of existing Secret containing extra env vars\n  ##\n  extraEnvVarsSecret: \"\"\n  ## @param proxy.extraVolumes Optionally specify extra list of additional volumes for Proxy pods\n  ##\n  extraVolumes: []\n  ## @param proxy.extraVolumeMounts Optionally specify extra list of additional volumeMounts for Proxy container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param proxy.initContainers Add additional init containers to the Proxy pods\n  ## Example:\n  ## initContainers:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  initContainers: []\n  ## @param proxy.sidecars Add additional sidecar containers to the Proxy pod\n  ## Example:\n  ## sidecars:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  sidecars: []\n\n  ## @section Proxy Traffic Exposure Parameters\n\n  ## Network policy\n  ##\n  networkPolicy:\n    ## @param proxy.networkPolicy.enabled Deploy Proxy network policies\n    ##\n    enabled: true\n    ## @param proxy.networkPolicy.allowInterspaceAccess Allow communication between pods in different namespaces\n    ##\n    allowInterspaceAccess: true\n    ## @param proxy.networkPolicy.extraIngress [string] Add extra ingress rules to the NetworkPolicy\n    ##\n    extraIngress: |\n      ## Any IP --\u003e Proxy\n      ##\n      - ports:\n          - port: {{ .Values.proxy.containerPort.http }}\n    ## @param proxy.networkPolicy.extraEgress Add extra egress rules to the NetworkPolicy\n    ##\n    extraEgress: \"\"\n  service:\n    api:\n      ## @param proxy.service.api.type API service type\n      ##\n      type: ClusterIP\n      ## @param proxy.service.api.port API service port\n      ##\n      port: 8001\n      ## @param proxy.service.api.loadBalancerIP API service LoadBalancer IP (optional, cloud specific)\n      ## ref: https://kubernetes.io/docs/user-guide/services/#type-loadbalancer\n      ##\n      loadBalancerIP: \"\"\n      ## @param proxy.service.api.loadBalancerSourceRanges loadBalancerIP source ranges for the Service\n      ##\n      loadBalancerSourceRanges: []\n      ## @param proxy.service.api.nodePorts.http NodePort for the HTTP endpoint\n      ## nodePorts:\n      ##   http: \u003cto set explicitly, choose port between 30000-32767\u003e\n      ##   https: \u003cto set explicitly, choose port between 30000-32767\u003e\n      ##\n      nodePorts:\n        http: \"\"\n      ## @param proxy.service.api.externalTrafficPolicy External traffic policy for the service\n      ## Enable client source IP preservation\n      ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n      ##\n      externalTrafficPolicy: Cluster\n    metrics:\n      ## @param proxy.service.metrics.type Metrics service type\n      ##\n      type: ClusterIP\n      ## @param proxy.service.metrics.port Metrics service port\n      ##\n      port: 8002\n      ## @param proxy.service.metrics.loadBalancerIP Metrics service LoadBalancer IP (optional, cloud specific)\n      ## ref: https://kubernetes.io/docs/user-guide/services/#type-loadbalancer\n      ##\n      loadBalancerIP: \"\"\n      ## @param proxy.service.metrics.loadBalancerSourceRanges loadBalancerIP source ranges for the Service\n      ##\n      loadBalancerSourceRanges: []\n      ## @param proxy.service.metrics.nodePorts.http NodePort for the HTTP endpoint\n      ## nodePorts:\n      ##   http: \u003cto set explicitly, choose port between 30000-32767\u003e\n      ##   https: \u003cto set explicitly, choose port between 30000-32767\u003e\n      ##\n      nodePorts:\n        http: \"\"\n      ## @param proxy.service.metrics.externalTrafficPolicy External traffic policy for the service\n      ## Enable client source IP preservation\n      ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n      ##\n      externalTrafficPolicy: Cluster\n    public:\n      ## @param proxy.service.public.type Public service type\n      ##\n      type: ClusterIP\n      # HTTP Port\n      ## @param proxy.service.public.port Public service port\n      ##\n      port: 80\n      ## @param proxy.service.public.loadBalancerIP Public service LoadBalancer IP (optional, cloud specific)\n      ## ref: https://kubernetes.io/docs/user-guide/services/#type-loadbalancer\n      ##\n      loadBalancerIP: \"\"\n      ## @param proxy.service.public.loadBalancerSourceRanges loadBalancerIP source ranges for the Service\n      ##\n      loadBalancerSourceRanges: []\n      ## @param proxy.service.public.nodePorts.http NodePort for the HTTP endpoint\n      ## nodePorts:\n      ##   http: \u003cto set explicitly, choose port between 30000-32767\u003e\n      ##   https: \u003cto set explicitly, choose port between 30000-32767\u003e\n      ##\n      nodePorts:\n        http: \"\"\n      ## @param proxy.service.public.externalTrafficPolicy External traffic policy for the service\n      ## Enable client source IP preservation\n      ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n      ##\n      externalTrafficPolicy: Cluster\n  ## Configure the ingress resource that allows you to access to your JupyterHub instance\n  ##\n  ingress:\n    ## @param proxy.ingress.enabled Set to true to enable ingress record generation\n    ##\n    enabled: false\n    ## @param proxy.ingress.apiVersion Force Ingress API version (automatically detected if not set)\n    ##\n    apiVersion: \"\"\n    ## @param proxy.ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)\n    ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster.\n    ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/\n    ##\n    ingressClassName: \"\"\n    ## @param proxy.ingress.path Path to the Proxy pod.\n    ##\n    path: /\n    ## @param proxy.ingress.pathType Ingress path type\n    ##\n    pathType: ImplementationSpecific\n    ## DEPRECATED: Use ingress.annotations instead of ingress.certManager\n    ## certManager: false\n    ##\n\n    ## When the ingress is enabled, a host pointing to this will be created\n    ## @param proxy.ingress.hostname Set ingress rule hostname\n    ##\n    hostname: jupyterhub.local\n    ## @param proxy.ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.\n    ## For a full list of possible ingress annotations, please see\n    ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md\n    ## Use this parameter to set the required annotations for cert-manager, see\n    ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations\n    ##\n    ## e.g:\n    ## annotations:\n    ##   kubernetes.io/ingress.class: nginx\n    ##   cert-manager.io/cluster-issuer: cluster-issuer-name\n    ##\n    annotations: {}\n    ## @param proxy.ingress.tls Enable ingress tls configuration for the hostname defined at proxy.ingress.hostname\n    ## TLS certificates will be retrieved from a TLS secret with name: {{- printf \"%s-tls\" .Values.ingress.hostname }}\n    ## You can use the ingress.secrets parameter to create this TLS secret, relay on cert-manager to create it, or\n    ## let the chart create self-signed certificates for you\n    ##\n    tls: false\n    ## @param proxy.ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm\n    ##\n    selfSigned: false\n    ## @param proxy.ingress.extraHosts The list of additional hostnames to be covered with this ingress record.\n    ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array\n    ## extraHosts:\n    ## - name: aspnet-core.local\n    ##   path: /\n    ##\n    extraHosts: []\n    ## @param proxy.ingress.extraTls The tls configuration for additional hostnames to be covered with this ingress record.\n    ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls\n    ## extraTls:\n    ## - hosts:\n    ##     - aspnet-core.local\n    ##   secretName: aspnet-core.local-tls\n    ##\n    extraTls: []\n    ## @param proxy.ingress.extraPaths Any additional arbitrary paths that may need to be added to the ingress under the main host.\n    ## For example: The ALB ingress controller requires a special rule for handling SSL redirection.\n    ##\n    extraPaths: []\n    ## @param proxy.ingress.secrets Add extra secrets for the tls configuration\n    ## If you're providing your own certificates, please use this to add the certificates as secrets\n    ## key and certificate should start with -----BEGIN CERTIFICATE----- or -----BEGIN RSA PRIVATE KEY-----\n    ## name should line up with a secretName set further up\n    ##\n    ## If it is not set and you're using cert-manager, this is unneeded, as it will create the secret for you\n    ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created\n    ## It is also possible to create and manage the certificates outside of this helm chart\n    ##\n    ## Please see README.md for more information\n    ## - name: aspnet-core.local-tls\n    ##   key:\n    ##   certificate:\n    ##\n    secrets: []\n\n  ## @section Proxy Metrics parameters\n\n  metrics:\n    ## Prometheus Operator ServiceMonitor configuration\n    ##\n    serviceMonitor:\n      ## @param proxy.metrics.serviceMonitor.enabled If the operator is installed in your cluster, set to true to create a Service Monitor Entry\n      ##\n      enabled: false\n      ## @param proxy.metrics.serviceMonitor.namespace Namespace which Prometheus is running in\n      ##\n      namespace: \"\"\n      ## @param proxy.metrics.serviceMonitor.path HTTP path to scrape for metrics\n      ##\n      path: /metrics\n      ## @param proxy.metrics.serviceMonitor.interval Interval at which metrics should be scraped\n      ##\n      interval: 30s\n      ## @param proxy.metrics.serviceMonitor.scrapeTimeout Specify the timeout after which the scrape is ended\n      ## e.g:\n      ## scrapeTimeout: 30s\n      scrapeTimeout: \"\"\n      ## @param proxy.metrics.serviceMonitor.relabellings Specify Metric Relabellings to add to the scrape endpoint\n      ##\n      relabellings: []\n      ## @param proxy.metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint\n      ##\n      honorLabels: false\n      ## @param proxy.metrics.serviceMonitor.additionalLabels Used to pass Labels that are required by the installed Prometheus Operator\n      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec\n      ##\n      additionalLabels: {}\n\n## @section Image puller deployment parameters\n\n## Image Puller deployment parameters\n##\nimagePuller:\n  ## @param imagePuller.enabled Deploy ImagePuller daemonset\n  ##\n  enabled: true\n  ## @param imagePuller.command Override ImagePuller default command\n  ##\n  command: []\n  ## @param imagePuller.args Override ImagePuller default args\n  ##\n  args: []\n  ## @param imagePuller.hostAliases Add deployment host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## imagePuller resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param imagePuller.resources.limits The resources limits for the container\n  ## @param imagePuller.resources.requests The requested resources for the container\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##   cpu: 200m\n    ##   memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##   cpu: 200m\n    ##   memory: 10Mi\n    requests: {}\n  ## imagePuller containers' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param imagePuller.containerSecurityContext.enabled Enabled ImagePuller containers' Security Context\n  ## @param imagePuller.containerSecurityContext.runAsUser Set ImagePuller container's Security Context runAsUser\n  ## @param imagePuller.containerSecurityContext.runAsNonRoot Set ImagePuller container's Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## imagePuller pods' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param imagePuller.podSecurityContext.enabled Enabled ImagePuller pods' Security Context\n  ## @param imagePuller.podSecurityContext.fsGroup Set ImagePuller pod's Security Context fsGroup\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## @param imagePuller.podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAffinityPreset: \"\"\n  ## @param imagePuller.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAntiAffinityPreset: soft\n  ## Node affinity preset\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ## @param imagePuller.nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ## @param imagePuller.nodeAffinityPreset.key Node label key to match. Ignored if `affinity` is set\n  ## @param imagePuller.nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set\n  ##\n  nodeAffinityPreset:\n    type: \"\"\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param imagePuller.affinity Affinity for pod assignment. Evaluated as a template.\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ##\n  affinity: {}\n  ## @param imagePuller.nodeSelector Node labels for pod assignment. Evaluated as a template.\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param imagePuller.tolerations Tolerations for pod assignment. Evaluated as a template.\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param imagePuller.podLabels Pod extra labels\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n  ##\n  podLabels: {}\n  ## @param imagePuller.podAnnotations Annotations for ImagePuller pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param imagePuller.priorityClassName ImagePuller pod priority class name\n  ## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n  ##\n  priorityClassName: \"\"\n  ## @param imagePuller.lifecycleHooks Add lifecycle hooks to the ImagePuller deployment\n  ##\n  lifecycleHooks: {}\n  ## @param imagePuller.customStartupProbe  Override default startup probe\n  ##\n  customStartupProbe: {}\n  ## @param imagePuller.customLivenessProbe  Override default liveness probe\n  ##\n  customLivenessProbe: {}\n  ## @param imagePuller.customReadinessProbe  Override default readiness probe\n  ##\n  customReadinessProbe: {}\n  ## @param imagePuller.updateStrategy.type Update strategy - only really applicable for deployments with RWO PVs attached\n  ## If replicas = 1, an update can get \"stuck\", as the previous pod remains attached to the\n  ## PV, and the \"incoming\" pod can never start. Changing the strategy to \"Recreate\" will\n  ## terminate the single previous pod, so that the new, incoming pod can attach to the PV\n  ##\n  updateStrategy:\n    type: RollingUpdate\n  ## @param imagePuller.extraEnvVars Add extra environment variables to the ImagePuller container\n  ## Example:\n  ## extraEnvVars:\n  ##   - name: FOO\n  ##     value: \"bar\"\n  ##\n  extraEnvVars: []\n  ## @param imagePuller.extraEnvVarsCM Name of existing ConfigMap containing extra env vars\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param imagePuller.extraEnvVarsSecret Name of existing Secret containing extra env vars\n  ##\n  extraEnvVarsSecret: \"\"\n  ## @param imagePuller.extraVolumes  Optionally specify extra list of additional volumes for ImagePuller pods\n  ##\n  extraVolumes: []\n  ## @param imagePuller.extraVolumeMounts  Optionally specify extra list of additional volumeMounts for ImagePuller container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param imagePuller.initContainers Add additional init containers to the ImagePuller pods\n  ## Example:\n  ## initContainers:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  initContainers: []\n  ## @param imagePuller.sidecars Add additional sidecar containers to the ImagePuller pod\n  ## Example:\n  ## sidecars:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  sidecars: []\n\n## @section Singleuser deployment parameters\n\n## Singleuser deployment parameters\n## NOTE: The values in this section are used for generating the hub.configuration value. In case you provide\n## a custom hub.configuration or a configmap, these will be ignored.\n## @param singleuser.image.registry Single User image registry\n## @param singleuser.image.repository Single User image repository\n## @param singleuser.image.tag Single User image tag (immutabe tags are recommended)\n## @param singleuser.image.pullPolicy Single User image pull policy\n## @param singleuser.image.pullSecrets Single User image pull secrets\n##\nsingleuser:\n  image:\n    registry: docker.io\n    repository: bitnami/jupyter-base-notebook\n    tag: 1.5.0-debian-10-r38\n    ## Specify a imagePullPolicy\n    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n    ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n    ##\n    ##\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## e.g:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## Command for running the container (set to default if not set). Use array form\n  ## @param singleuser.command Override Single User default command\n  ##\n  command: []\n  ## @param singleuser.tolerations Tolerations for pod assignment. Evaluated as a template.\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param singleuser.containerPort Single User container port\n  ##\n  containerPort: 8888\n  ## @param singleuser.notebookDir Notebook directory (it will be the same as the PVC volume mount)\n  ##\n  notebookDir: /opt/bitnami/jupyterhub-singleuser\n  ## singleuser resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param singleuser.resources.limits The resources limits for the container\n  ## @param singleuser.resources.requests The requested resources for the container\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##   cpu: 200m\n    ##   memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##   cpu: 200m\n    ##   memory: 10Mi\n    requests: {}\n  ## singleuser containers' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param singleuser.containerSecurityContext.enabled Enabled Single User containers' Security Context\n  ## @param singleuser.containerSecurityContext.runAsUser Set Single User container's Security Context runAsUser\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n  ## singleuser pods' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param singleuser.podSecurityContext.enabled Enabled Single User pods' Security Context\n  ## @param singleuser.podSecurityContext.fsGroup Set Single User pod's Security Context fsGroup\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## @param singleuser.nodeSelector Node labels for pod assignment. Evaluated as a template.\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param singleuser.podLabels Extra labels for Single User pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n  ##\n  podLabels: {}\n  ## @param singleuser.podAnnotations Annotations for Single User pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param singleuser.priorityClassName Single User pod priority class name\n  ## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n  ##\n  priorityClassName: \"\"\n  ## @param singleuser.lifecycleHooks Add lifecycle hooks to the Single User deployment to automate configuration before or after startup\n  ##\n  lifecycleHooks: {}\n  ## @param singleuser.extraEnvVars Add extra environment variables to the Single User container\n  ## Example:\n  ## extraEnvVars:\n  ##   - name: FOO\n  ##     value: \"bar\"\n  ##\n  extraEnvVars: []\n  ## @param singleuser.extraVolumes Optionally specify extra list of additional volumes for Single User pods\n  ##\n  extraVolumes: []\n  ## @param singleuser.extraVolumeMounts Optionally specify extra list of additional volumeMounts for Single User container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param singleuser.initContainers  Add additional init containers to the Single User pods\n  ## Example:\n  ## initContainers:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  initContainers: []\n  ## @param singleuser.sidecars  Add additional sidecar containers to the Single User pod\n  ## Example:\n  ## sidecars:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  sidecars: []\n\n  ## @section Single User RBAC parameters\n\n  ## Service account parameters\n  ##\n  serviceAccount:\n    ## @param singleuser.serviceAccount.create Specifies whether a ServiceAccount should be created\n    ##\n    create: true\n    ## @param singleuser.serviceAccount.name Override Single User service account name\n    ## If not set and create is true, a name is generated using the fullname template\n    ##\n    name: \"\"\n\n  ## @section Single User Persistence parameters\n\n  ## Enable persistence using Persistent Volume Claims\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/\n  ##\n  persistence:\n    ## @param singleuser.persistence.enabled Enable persistent volume creation on Single User instances\n    ## If true, use a Persistent Volume Claim, If false, use emptyDir\n    ##\n    enabled: true\n    ## @param singleuser.persistence.storageClass Persistent Volumes storage class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    storageClass: \"\"\n    ## @param singleuser.persistence.accessModes Persistent Volumes access modes\n    ##\n    accessModes:\n      - ReadWriteOnce\n    ## @param singleuser.persistence.size Persistent Volumes size\n    ##\n    size: 10Gi\n\n  ## @section Traffic exposure parameters\n\n  ## Network policy\n  ##\n  networkPolicy:\n    ## @param singleuser.networkPolicy.enabled Deploy Single User network policies\n    ##\n    enabled: true\n    ## @param singleuser.networkPolicy.allowInterspaceAccess Allow communication between pods in different namespaces\n    ##\n    allowInterspaceAccess: true\n    ## @param singleuser.networkPolicy.allowCloudMetadataAccess Allow Single User pods to access Cloud Metada endpoints\n    ##\n    allowCloudMetadataAccess: false\n    ## @param singleuser.networkPolicy.extraIngress Add extra ingress rules to the NetworkPolicy\n    ##\n    extraIngress: \"\"\n    ## @param singleuser.networkPolicy.extraEgress Add extra egress rules to the NetworkPolicy\n    ##\n    extraEgress: \"\"\n\n## @section Auxiliary image parameters\n\n## @param auxiliaryImage.registry Auxiliary image registry\n## @param auxiliaryImage.repository Auxiliary image repository\n## @param auxiliaryImage.tag Auxiliary image tag (immutabe tags are recommended)\n## @param auxiliaryImage.pullPolicy Auxiliary image pull policy\n## @param auxiliaryImage.pullSecrets Auxiliary image pull secrets\n##\nauxiliaryImage:\n  registry: docker.io\n  repository: bitnami/bitnami-shell\n  tag: 10-debian-10-r285\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ## e.g:\n  ## pullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  pullSecrets: []\n\n## @section External Database settings\n\n## External Database Configuration\n## All of these values are only used when postgresql.enabled is set to false\n##\nexternalDatabase:\n  ## @param externalDatabase.host Host of an external PostgreSQL instance to connect (only if postgresql.enabled=false)\n  ##\n  host: \"\"\n  ## @param externalDatabase.user User of an external PostgreSQL instance to connect (only if postgresql.enabled=false)\n  ##\n  user: postgres\n  ## @param externalDatabase.password Password of an external PostgreSQL instance to connect (only if postgresql.enabled=false)\n  ##\n  password: \"\"\n  ## @param externalDatabase.existingSecret Secret containing the password of an external PostgreSQL instance to connect (only if postgresql.enabled=false)\n  ## Name of an existing secret resource containing the DB password in a 'postgresql-password' key\n  ##\n  existingSecret: \"\"\n  ## @param externalDatabase.database Database inside an external PostgreSQL to connect (only if postgresql.enabled=false)\n  ##\n  database: jupyterhub\n  ## @param externalDatabase.port Port of an external PostgreSQL to connect (only if postgresql.enabled=false)\n  ##\n  port: 5432\n\n## @section PostgreSQL subchart settings\n\n## PostgreSQL chart configuration\n## https://github.com/bitnami/charts/blob/master/bitnami/postgresql/values.yaml\n##\npostgresql:\n  ## @param postgresql.enabled Deploy PostgreSQL subchart\n  ##\n  enabled: true\n  ## @param postgresql.nameOverride Override name of the PostgreSQL chart\n  ##\n  nameOverride: \"\"\n  ## @param postgresql.existingSecret Existing secret containing the password of the PostgreSQL chart\n  ##\n  existingSecret: \"\"\n  ## @param postgresql.postgresqlPassword Password for the postgres user of the PostgreSQL chart (auto-generated if not set)\n  ## ref: https://hub.docker.com/_/postgres/\n  ##\n  postgresqlPassword: \"\"\n  ## @param postgresql.postgresqlUsername Username to create when deploying the PostgreSQL chart\n  ##\n  postgresqlUsername: bn_jupyterhub\n  ## @param postgresql.postgresqlDatabase Database to create when deploying the PostgreSQL chart\n  ##\n  postgresqlDatabase: bitnami_jupyterhub\n  ## PostgreSQL service\n  ##\n  service:\n    ## @param postgresql.service.port PostgreSQL service port\n    ##\n    port: 5432\n  ## Enable persistence using Persistent Volume Claims\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/\n  ##\n  persistence:\n    ## @param postgresql.persistence.enabled Use PVCs when deploying the PostgreSQL chart\n    ##\n    enabled: true\n    ## @param postgresql.persistence.existingClaim Use an existing PVC when deploying the PostgreSQL chart\n    ##\n    existingClaim: \"\"\n    ## @param postgresql.persistence.storageClass storageClass of the created PVCs\n    ## postgresql data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    storageClass: \"\"\n    ## @param postgresql.persistence.accessMode Access mode of the created PVCs\n    ##\n    accessMode: ReadWriteOnce\n    ## @param postgresql.persistence.size Size of the created PVCs\n    ##\n    size: 8Gi\n"
            ],
            "verify": false,
            "version": "0.3.6",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "module.kube.kubernetes_namespace.mlflow",
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub",
            "module.kube.kubernetes_namespace.keycloak",
            "module.kube.kubernetes_namespace.ldap",
            "module.kube.kubernetes_namespace.mariadb"
          ]
        }
      ]
    },
    {
      "module": "module.keycloak_install",
      "mode": "managed",
      "type": "helm_release",
      "name": "keycloak",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "keycloak",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "keycloak",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "15.0.2",
                "chart": "keycloak",
                "name": "keycloak",
                "namespace": "keycloak",
                "revision": 1,
                "values": "{\"affinity\":{},\"args\":[],\"auth\":{\"adminPassword\":\"admin\",\"adminUser\":\"lakehouse_admin\",\"createAdminUser\":true,\"existingSecret\":\"\",\"existingSecretPerPassword\":{},\"managementPassword\":\"\",\"managementUser\":\"manager\",\"tls\":{\"autoGenerated\":false,\"enabled\":false,\"existingSecret\":\"\",\"jksSecret\":\"\",\"keystoreFilename\":\"\",\"keystorePassword\":\"\",\"resources\":{\"limits\":{},\"requests\":{}},\"truststoreFilename\":\"\",\"truststorePassword\":\"\"}},\"autoscaling\":{\"enabled\":false,\"maxReplicas\":11,\"minReplicas\":1,\"targetCPU\":\"\",\"targetMemory\":\"\"},\"cache\":{\"authOwnersCount\":1,\"ownersCount\":1},\"clusterDomain\":\"cluster.local\",\"command\":[],\"commonAnnotations\":{},\"commonLabels\":{},\"configuration\":\"\",\"containerPorts\":{\"http\":8080,\"https\":8443},\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"existingConfigmap\":\"\",\"externalDatabase\":{\"database\":\"bitnami_keycloak\",\"existingSecret\":\"\",\"host\":\"\",\"password\":\"\",\"port\":5432,\"user\":\"bn_keycloak\"},\"extraDeploy\":[],\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraStartupArgs\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"storageClass\":\"\"},\"hostAliases\":[],\"image\":{\"debug\":false,\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/keycloak\",\"tag\":\"15.0.2-debian-10-r94\"},\"ingress\":{\"annotations\":{},\"apiVersion\":\"\",\"enabled\":false,\"existingSecret\":\"\",\"extraHosts\":[],\"extraTls\":[],\"hostname\":\"keycloak.local\",\"ingressClassName\":\"\",\"path\":\"/\",\"pathType\":\"ImplementationSpecific\",\"secrets\":[],\"servicePort\":\"https\",\"tls\":false},\"initContainers\":[],\"initdbScripts\":{},\"initdbScriptsConfigMap\":\"\",\"keycloakConfigCli\":{\"annotations\":{\"helm.sh/hook\":\"post-install,post-upgrade,post-rollback\",\"helm.sh/hook-delete-policy\":\"hook-succeeded,before-hook-creation\",\"helm.sh/hook-weight\":\"5\"},\"args\":[],\"backoffLimit\":1,\"command\":[],\"configuration\":{},\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"enabled\":false,\"existingConfigmap\":\"\",\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/keycloak-config-cli\",\"tag\":\"4.3.0-debian-10-r54\"},\"podAnnotations\":{},\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"resources\":{\"limits\":{},\"requests\":{}}},\"kubeVersion\":\"\",\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"httpGet\":{\"path\":\"/auth/\",\"port\":\"http\"},\"initialDelaySeconds\":300,\"periodSeconds\":1,\"successThreshold\":1,\"timeoutSeconds\":5},\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{\"prometheus.io/port\":\"{{ .Values.metrics.service.port }}\",\"prometheus.io/scrape\":\"true\"},\"port\":9990},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"namespace\":\"\",\"relabellings\":[],\"scrapeTimeout\":\"\"}},\"nameOverride\":\"\",\"networkPolicy\":{\"additionalRules\":{},\"allowExternal\":true,\"enabled\":false},\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"pdb\":{\"create\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"postgresql\":{\"enabled\":true,\"existingSecret\":\"\",\"persistence\":{\"enabled\":true},\"postgresqlDatabase\":\"bitnami_keycloak\",\"postgresqlPassword\":\"\",\"postgresqlUsername\":\"bn_keycloak\"},\"priorityClassName\":\"\",\"proxyAddressForwarding\":true,\"rbac\":{\"create\":false,\"rules\":[]},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"httpGet\":{\"path\":\"/auth/realms/master\",\"port\":\"http\"},\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicaCount\":1,\"resources\":{\"limits\":{},\"requests\":{}},\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"externalTrafficPolicy\":\"Cluster\",\"httpsPort\":443,\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"http\":\"\",\"https\":\"\"},\"port\":80,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"automountServiceAccountToken\":false,\"create\":true,\"name\":\"\"},\"serviceDiscovery\":{\"enabled\":false,\"properties\":[],\"protocol\":\"kubernetes.KUBE_PING\",\"transportStack\":\"tcp\"},\"sidecars\":[],\"startupProbe\":{\"enabled\":false,\"failureThreshold\":60,\"httpGet\":{\"path\":\"/auth/\",\"port\":\"http\"},\"initialDelaySeconds\":30,\"periodSeconds\":5,\"successThreshold\":1,\"timeoutSeconds\":1},\"tolerations\":[],\"updateStrategy\":{\"type\":\"RollingUpdate\"}}",
                "version": "5.2.2"
              }
            ],
            "name": "keycloak",
            "namespace": "keycloak",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://charts.bitnami.com/bitnami",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 1000,
            "values": [
              "## @section Global parameters\n## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass\n\n## @param global.imageRegistry Global Docker image registry\n## @param global.imagePullSecrets Global Docker registry secret names as an array\n## @param global.storageClass Global StorageClass for Persistent Volume(s)\n##\nglobal:\n  imageRegistry: \"\"\n  ## E.g.\n  ## imagePullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  imagePullSecrets: []\n  storageClass: \"\"\n\n## @section Common parameters\n\n## @param kubeVersion Force target Kubernetes version (using Helm capabilities if not set)\n##\nkubeVersion: \"\"\n## @param nameOverride String to partially override keycloak.fullname\n##\nnameOverride: \"\"\n## @param fullnameOverride String to fully override keycloak.fullname\n##\nfullnameOverride: \"\"\n## @param hostAliases Add deployment host aliases\n## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n##\nhostAliases: []\n## @param commonLabels Labels to add to all deployed objects\n##\ncommonLabels: {}\n## @param commonAnnotations Annotations to add to all deployed objects\n##\ncommonAnnotations: {}\n## @param clusterDomain Default Kubernetes cluster domain\n##\nclusterDomain: cluster.local\n## @param extraDeploy Array of extra objects to deploy with the release\n##\nextraDeploy: []\n\n## @section Keycloak parameters\n\n## Bitnami Keycloak image version\n## ref: https://hub.docker.com/r/bitnami/keycloak/tags/\n## @param image.registry Keycloak image registry\n## @param image.repository Keycloak image repository\n## @param image.tag Keycloak image tag (immutable tags are recommended)\n## @param image.pullPolicy Keycloak image pull policy\n## @param image.pullSecrets Specify docker-registry secret names as an array\n## @param image.debug Specify if debug logs should be enabled\n##\nimage:\n  registry: docker.io\n  repository: bitnami/keycloak\n  tag: 15.0.2-debian-10-r94\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ## Example:\n  ## pullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  pullSecrets: []\n  ## Set to true if you would like to see extra information on logs\n  ##\n  debug: false\n## Keycloak authentication parameters\n## ref: https://github.com/bitnami/bitnami-docker-keycloak#admin-credentials\n##\nauth:\n  ## @param auth.createAdminUser Create administrator user on boot\n  ##\n  createAdminUser: true\n  ## @param auth.adminUser Keycloak administrator user\n  ##\n  adminUser: lakehouse_admin\n  ## @param auth.adminPassword Keycloak administrator password for the new user\n  ##\n  adminPassword: \"admin\"\n  ## @param auth.managementUser Wildfly management user\n  ##\n  managementUser: manager\n  ## @param auth.managementPassword Wildfly management password\n  ##\n  managementPassword: \"\"\n  ## @param auth.existingSecret An already existing secret containing auth info\n  ## e.g:\n  ## existingSecret:\n  ##   name: mySecret\n  ##   keyMapping:\n  ##     admin-password: myPasswordKey\n  ##     management-password: myManagementPasswordKey\n  ##     database-password: myDatabasePasswordKey\n  ##     tls-keystore-password: myTlsKeystorePasswordKey\n  ##     tls-truestore-password: myTlsTruestorePasswordKey\n  ##\n  existingSecret: \"\"\n  ## @param auth.existingSecretPerPassword Override `existingSecret` and other secret values\n  ## e.g:\n  ## existingSecretPerPassword:\n  ##   keyMapping:\n  ##     adminPassword: KEYCLOAK_ADMIN_PASSWORD\n  ##     managementPassword: KEYCLOAK_MANAGEMENT_PASSWORD\n  ##     databasePassword: password\n  ##     tlsKeystorePassword: JKS_KEYSTORE_TRUSTSTORE_PASSWORD\n  ##     tlsTruststorePassword: JKS_KEYSTORE_TRUSTSTORE_PASSWORD\n  ##   adminPassword:\n  ##     name: keycloak-test2.credentials ## release-name\n  ##   managementPassword:\n  ##     name: keycloak-test2.credentials\n  ##   databasePassword:\n  ##     name: keycloak.pocwatt-keycloak-cluster.credentials\n  ##   tlsKeystorePassword:\n  ##     name: keycloak-test2.credentials\n  ##   tlsTruststorePassword:\n  ##     name: keycloak-test2.credentials\n  ##\n  existingSecretPerPassword: {}\n  ## TLS encryption parameters\n  ## ref: https://github.com/bitnami/bitnami-docker-keycloak#tls-encryption\n  ##\n  tls:\n    ## @param auth.tls.enabled Enable TLS encryption\n    ##\n    enabled: false\n    ## @param auth.tls.autoGenerated Generate automatically self-signed TLS certificates. Currently only supports PEM certificates\n    ##\n    autoGenerated: false\n    ## @param auth.tls.existingSecret Existing secret containing the TLS certificates per Keycloak replica\n    ## Create this secret following the steps below:\n    ## 1) Generate your trustore and keystore files (more info at https://www.keycloak.org/docs/latest/server_installation/#_setting_up_ssl)\n    ## 2) Rename your truststore to `keycloak.truststore.jks`.\n    ## 3) Rename your keystores to `keycloak-X.keystore.jks` where X is the ID of each Keycloak replica\n    ## 4) Run the command below where SECRET_NAME is the name of the secret you want to create:\n    ##       kubectl create secret generic SECRET_NAME --from-file=./keycloak.truststore.jks --from-file=./keycloak-0.keystore.jks --from-file=./keycloak-1.keystore.jks ...\n    ##\n    existingSecret: \"\"\n    ## @param auth.tls.truststoreFilename Truststore specific filename inside the existing secret\n    ## Note: Setting up this value, you will use the same trustore file in all the replicas\n    ##\n    truststoreFilename: \"\"\n    ## @param auth.tls.keystoreFilename Keystore specific filename inside the existing secret\n    ## Note: Setting up this value, you will use the same trustore file in all the replicas\n    ##\n    keystoreFilename: \"\"\n    ## @param auth.tls.jksSecret DEPRECATED. Use `auth.tls.existingSecret` instead\n    ##\n    jksSecret: \"\"\n    ## @param auth.tls.keystorePassword Password to access the keystore when it's password-protected\n    ##\n    keystorePassword: \"\"\n    ## @param auth.tls.truststorePassword Password to access the truststore when it's password-protected\n    ##\n    truststorePassword: \"\"\n    ## Init containers' resource requests and limits\n    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n    ## We usually recommend not to specify default resources and to leave this as a conscious\n    ## choice for the user. This also increases chances charts run on environments with little\n    ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n    ## @param auth.tls.resources.limits The resources limits for the TLS init container\n    ## @param auth.tls.resources.requests The requested resources for the TLS init container\n    ##\n    resources:\n      ## Example:\n      ## limits:\n      ##    cpu: 100m\n      ##    memory: 128Mi\n      limits: {}\n      ## Examples:\n      ## requests:\n      ##    cpu: 100m\n      ##    memory: 128Mi\n      requests: {}\n## @param proxyAddressForwarding Enable Proxy Address Forwarding\n## ref: https://www.keycloak.org/docs/latest/server_installation/#_setting-up-a-load-balancer-or-proxy\n##\nproxyAddressForwarding: true\n## Keycloak Service Discovery settings\n## ref: https://github.com/bitnami/bitnami-docker-keycloak#cluster-configuration\n##\nserviceDiscovery:\n  ## @param serviceDiscovery.enabled Enable Service Discovery for Keycloak (required if `replicaCount` \u003e `1`)\n  ##\n  enabled: false\n  ## @param serviceDiscovery.protocol Sets the protocol that Keycloak nodes would use to discover new peers\n  ## Available protocols can be found at http://www.jgroups.org/javadoc3/org/jgroups/protocols/\n  ##\n  protocol: kubernetes.KUBE_PING\n  ## @param serviceDiscovery.properties Properties for the discovery protocol set in `serviceDiscovery.protocol` parameter\n  ## List of key=\u003evalue pairs\n  ## Example:\n  ## properties:\n  ##   - datasource_jndi_name=\u003e\"java:jboss/datasources/KeycloakDS\"\n  ##   - initialize_sql=\u003e\"CREATE TABLE IF NOT EXISTS JGROUPSPING ( own_addr varchar(200) NOT NULL, cluster_name varchar(200) NOT NULL, created timestamp default current_timestamp, ping_data BYTEA, constraint PK_JGROUPSPING PRIMARY KEY (own_addr, cluster_name))\"\n  ##\n  properties: []\n  ## @param serviceDiscovery.transportStack Transport stack for the discovery protocol set in `serviceDiscovery.protocol` parameter\n  ##\n  transportStack: tcp\n## Keycloak cache settings\n## ref: https://github.com/bitnami/bitnami-docker-keycloak#cluster-configuration\n##\ncache:\n  ## @param cache.ownersCount Number of nodes that will replicate cached data\n  ##\n  ownersCount: 1\n  ## @param cache.authOwnersCount Number of nodes that will replicate cached authentication data\n  ##\n  authOwnersCount: 1\n## @param configuration Keycloak Configuration. Auto-generated based on other parameters when not specified\n## Specify content for standalone-ha.xml\n## NOTE: This will override configuring Keycloak based on environment variables (including those set by the chart)\n## The standalone-ha.xml is auto-generated based on other parameters when this parameter is not specified\n##\n## Example:\n## configuration: |-\n##    foo: bar\n##    baz:\n##\nconfiguration: \"\"\n## @param existingConfigmap Name of existing ConfigMap with Keycloak configuration\n## NOTE: When it's set the configuration parameter is ignored\n##\nexistingConfigmap: \"\"\n## @param extraStartupArgs Extra default startup args\n##\nextraStartupArgs: \"\"\n## @param initdbScripts Dictionary of initdb scripts\n## Specify dictionary of scripts to be run at first boot\n## ref: https://github.com/bitnami/bitnami-docker-keycloak#initializing-a-new-instance\n## Example:\n## initdbScripts:\n##   my_init_script.sh: |\n##      #!/bin/bash\n##      echo \"Do something.\"\n##\ninitdbScripts: {}\n## @param initdbScriptsConfigMap ConfigMap with the initdb scripts (Note: Overrides `initdbScripts`)\n##\ninitdbScriptsConfigMap: \"\"\n## @param command Override default container command (useful when using custom images)\n##\ncommand: []\n## @param args Override default container args (useful when using custom images)\n##\nargs: []\n## @param extraEnvVars Extra environment variables to be set on Keycloak container\n## Example:\n## extraEnvVars:\n##   - name: FOO\n##     value: \"bar\"\n##\nextraEnvVars: []\n## @param extraEnvVarsCM Name of existing ConfigMap containing extra env vars\n##\nextraEnvVarsCM: \"\"\n## @param extraEnvVarsSecret Name of existing Secret containing extra env vars\n##\nextraEnvVarsSecret: \"\"\n\n## @section keycloak-config-cli parameters\n\n## Configuration for keycloak-config-cli\n## ref: https://github.com/adorsys/keycloak-config-cli\n##\nkeycloakConfigCli:\n  ## @param keycloakConfigCli.enabled Whether to enable keycloak-config-cli\n  ##\n  enabled: false\n  ## Bitnami keycloak-config-cli image\n  ## ref: https://hub.docker.com/r/bitnami/keycloak-config-cli/tags/\n  ## @param keycloakConfigCli.image.registry keycloak-config-cli container image registry\n  ## @param keycloakConfigCli.image.repository keycloak-config-cli container image repository\n  ## @param keycloakConfigCli.image.tag keycloak-config-cli container image tag\n  ## @param keycloakConfigCli.image.pullPolicy keycloak-config-cli container image pull policy\n  ## @param keycloakConfigCli.image.pullSecrets keycloak-config-cli container image pull secrets\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/keycloak-config-cli\n    tag: 4.3.0-debian-10-r54\n    ## Specify a imagePullPolicy\n    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n    ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n    ##\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## e.g:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## @param keycloakConfigCli.annotations [object] Annotations for keycloak-config-cli job\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  annotations:\n    helm.sh/hook: \"post-install,post-upgrade,post-rollback\"\n    helm.sh/hook-delete-policy: \"hook-succeeded,before-hook-creation\"\n    helm.sh/hook-weight: \"5\"\n  ## @param keycloakConfigCli.command Command for running the container (set to default if not set). Use array form\n  ##\n  command: []\n  ## @param keycloakConfigCli.args Args for running the container (set to default if not set). Use array form\n  ##\n  args: []\n  ## @param keycloakConfigCli.hostAliases Job pod host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## Keycloak config CLI resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param keycloakConfigCli.resources.limits The resources limits for the keycloak-config-cli container\n  ## @param keycloakConfigCli.resources.requests The requested resources for the keycloak-config-cli container\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 200m\n    ##    memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 200m\n    ##    memory: 10Mi\n    requests: {}\n  ## keycloak-config-cli containers' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param keycloakConfigCli.containerSecurityContext.enabled Enabled keycloak-config-cli containers' Security Context\n  ## @param keycloakConfigCli.containerSecurityContext.runAsUser Set keycloak-config-cli container's Security Context runAsUser\n  ## @param keycloakConfigCli.containerSecurityContext.runAsNonRoot Set keycloak-config-cli container's Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## keycloak-config-cli pods' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param keycloakConfigCli.podSecurityContext.enabled Enabled keycloak-config-cli pods' Security Context\n  ## @param keycloakConfigCli.podSecurityContext.fsGroup Set keycloak-config-cli pod's Security Context fsGroup\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## @param keycloakConfigCli.backoffLimit Number of retries before considering a Job as failed\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/job/#pod-backoff-failure-policy\n  ##\n  backoffLimit: 1\n  ## @param keycloakConfigCli.podLabels Pod extra labels\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n  ##\n  podLabels: {}\n  ## @param keycloakConfigCli.podAnnotations Annotations for job pod\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param keycloakConfigCli.extraEnvVars Additional environment variables to set\n  ## Example:\n  ## extraEnvVars:\n  ##   - name: FOO\n  ##     value: \"bar\"\n  ##\n  extraEnvVars: []\n  ## @param keycloakConfigCli.extraEnvVarsCM ConfigMap with extra environment variables\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param keycloakConfigCli.extraEnvVarsSecret Secret with extra environment variables\n  ##\n  extraEnvVarsSecret: \"\"\n  ## @param keycloakConfigCli.extraVolumes Extra volumes to add to the job\n  ##\n  extraVolumes: []\n  ## @param keycloakConfigCli.extraVolumeMounts Extra volume mounts to add to the container\n  ##\n  extraVolumeMounts: []\n  ## @param keycloakConfigCli.configuration keycloak-config-cli realms configuration\n  ## NOTE: nil keys will be considered files to import locally\n  ## Example:\n  ## configuration:\n  ##   realm1.json: |\n  ##     {\n  ##       \"realm\": \"realm1\",\n  ##       \"clients\": []\n  ##     }\n  ##   files/realm2.yaml:\n  ##   realm3.yaml: |\n  ##     realm: realm3\n  ##     clients: []\n  ##\n  configuration: {}\n  ## @param keycloakConfigCli.existingConfigmap ConfigMap with keycloak-config-cli configuration. This will override `keycloakConfigCli.config`\n  ## NOTE: This will override keycloakConfigCli.configuration\n  ##\n  existingConfigmap: \"\"\n\n## @section Keycloak deployment/statefulset parameters\n\n## @param replicaCount Number of Keycloak replicas to deploy\n##\nreplicaCount: 1\n## @param containerPorts [object] Keycloak container ports to open\n##\ncontainerPorts:\n  http: 8080\n  https: 8443\n## Keycloak containers' SecurityContext\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n## @param podSecurityContext.enabled Enabled Keykloak pods' Security Context\n## @param podSecurityContext.fsGroup Set Keykloak pod's Security Context fsGroup\n##\npodSecurityContext:\n  enabled: true\n  fsGroup: 1001\n## Keycloak pods' Security Context\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n## @param containerSecurityContext.enabled Enabled Keykloak containers' Security Context\n## @param containerSecurityContext.runAsUser Set Keykloak container's Security Context runAsUser\n## @param containerSecurityContext.runAsNonRoot Set Keykloak container's Security Context runAsNonRoot\n##\ncontainerSecurityContext:\n  enabled: true\n  runAsUser: 1001\n  runAsNonRoot: true\n## Keycloak resource requests and limits\n## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n## We usually recommend not to specify default resources and to leave this as a conscious\n## choice for the user. This also increases chances charts run on environments with little\n## resources, such as Minikube. If you do want to specify resources, uncomment the following\n## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n## @param resources.limits The resources limits for the Keycloak container\n## @param resources.requests The requested resources for the Keycloak container\n##\nresources:\n  ## Example:\n  ## limits:\n  ##    cpu: 200m\n  ##    memory: 256Mi\n  limits: {}\n  ## Examples:\n  ## requests:\n  ##    cpu: 200m\n  ##    memory: 10Mi\n  requests: {}\n## Configure extra options for startup probe\n## When enabling this, make sure to set initialDelaySeconds to 0 for livenessProbe and readinessProbe\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n## @param startupProbe.enabled Enable startupProbe\n## @param startupProbe.httpGet.path Request path for startupProbe\n## @param startupProbe.httpGet.port Port for startupProbe\n## @param startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n## @param startupProbe.periodSeconds Period seconds for startupProbe\n## @param startupProbe.timeoutSeconds Timeout seconds for startupProbe\n## @param startupProbe.failureThreshold Failure threshold for startupProbe\n## @param startupProbe.successThreshold Success threshold for startupProbe\n##\nstartupProbe:\n  enabled: false\n  httpGet:\n    path: /auth/\n    port: http\n  initialDelaySeconds: 30\n  periodSeconds: 5\n  timeoutSeconds: 1\n  failureThreshold: 60\n  successThreshold: 1\n## Configure extra options for liveness probe\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n## @param livenessProbe.enabled Enable livenessProbe\n## @param livenessProbe.httpGet.path Request path for livenessProbe\n## @param livenessProbe.httpGet.port Port for livenessProbe\n## @param livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n## @param livenessProbe.periodSeconds Period seconds for livenessProbe\n## @param livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n## @param livenessProbe.failureThreshold Failure threshold for livenessProbe\n## @param livenessProbe.successThreshold Success threshold for livenessProbe\n##\nlivenessProbe:\n  enabled: true\n  httpGet:\n    path: /auth/\n    port: http\n  initialDelaySeconds: 300\n  periodSeconds: 1\n  timeoutSeconds: 5\n  failureThreshold: 3\n  successThreshold: 1\n## Configure extra options for readiness probe\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n## @param readinessProbe.enabled Enable readinessProbe\n## @param readinessProbe.httpGet.path Request path for readinessProbe\n## @param readinessProbe.httpGet.port Port for readinessProbe\n## @param readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n## @param readinessProbe.periodSeconds Period seconds for readinessProbe\n## @param readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n## @param readinessProbe.failureThreshold Failure threshold for readinessProbe\n## @param readinessProbe.successThreshold Success threshold for readinessProbe\n##\nreadinessProbe:\n  enabled: true\n  httpGet:\n    path: /auth/realms/master\n    port: http\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  timeoutSeconds: 1\n  failureThreshold: 3\n  successThreshold: 1\n## @param customStartupProbe Custom Startup probes for Keycloak\n##\ncustomStartupProbe: {}\n## @param customLivenessProbe Custom Liveness probes for Keycloak\n##\ncustomLivenessProbe: {}\n## @param customReadinessProbe Custom Rediness probes Keycloak\n##\ncustomReadinessProbe: {}\n## Strategy to use to update Pods\n##\nupdateStrategy:\n  ## @param updateStrategy.type StrategyType\n  ## Can be set to RollingUpdate or OnDelete\n  ##\n  type: RollingUpdate\n## @param podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n##\npodAffinityPreset: \"\"\n## @param podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n##\npodAntiAffinityPreset: soft\n## Node affinity preset\n## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n##\nnodeAffinityPreset:\n  ## @param nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ##\n  type: \"\"\n  ## @param nodeAffinityPreset.key Node label key to match. Ignored if `affinity` is set.\n  ## E.g.\n  ## key: \"kubernetes.io/e2e-az-name\"\n  ##\n  key: \"\"\n  ## @param nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set.\n  ## E.g.\n  ## values:\n  ##   - e2e-az1\n  ##   - e2e-az2\n  ##\n  values: []\n## @param affinity Affinity for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n## @param nodeSelector Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n## @param tolerations Tolerations for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n## @param podLabels Extra labels for Keycloak pods\n## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n##\npodLabels: {}\n## @param podAnnotations Annotations for Keycloak pods\n## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n##\npodAnnotations: {}\n## @param priorityClassName Keycloak pods' priority.\n## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n##\npriorityClassName: \"\"\n## @param lifecycleHooks LifecycleHooks to set additional configuration at startup\n##\nlifecycleHooks: {}\n## @param extraVolumes Optionally specify extra list of additional volumes for Keycloak pods\n##\nextraVolumes: []\n## @param extraVolumeMounts Optionally specify extra list of additional volumeMounts for Keycloak container(s)\n##\nextraVolumeMounts: []\n## @param initContainers Add additional init containers to the Keycloak pods\n## Example:\n## initContainers:\n##   - name: your-image-name\n##     image: your-image\n##     imagePullPolicy: Always\n##     ports:\n##       - name: portname\n##         containerPort: 1234\n##\ninitContainers: []\n## @param sidecars Add additional sidecar containers to the Keycloak pods\n## Example:\n## sidecars:\n##   - name: your-image-name\n##     image: your-image\n##     imagePullPolicy: Always\n##     ports:\n##       - name: portname\n##         containerPort: 1234\n##\nsidecars: []\n\n## @section Exposure parameters\n\n## Service configuration\n##\nservice:\n  ## @param service.type Kubernetes service type\n  ##\n  type: ClusterIP\n  ## @param service.port Service HTTP port\n  ##\n  port: 80\n  ## @param service.httpsPort HTTPS Port\n  ##\n  httpsPort: 443\n  ## @param service.nodePorts [object] Specify the nodePort values for the LoadBalancer and NodePort service types.\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n  ##\n  nodePorts:\n    http: \"\"\n    https: \"\"\n  ## @param service.clusterIP Keycloak service clusterIP IP\n  ## e.g:\n  ## clusterIP: None\n  ##\n  clusterIP: \"\"\n  ## @param service.loadBalancerIP loadBalancerIP for the SuiteCRM Service (optional, cloud specific)\n  ## ref: https://kubernetes.io/docs/user-guide/services/#type-loadbalancer\n  ##\n  loadBalancerIP: \"\"\n  ## @param service.loadBalancerSourceRanges Address that are allowed when service is LoadBalancer\n  ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n  ## Example:\n  ## loadBalancerSourceRanges:\n  ##   - 10.10.10.0/24\n  ##\n  loadBalancerSourceRanges: []\n  ## @param service.externalTrafficPolicy Enable client source IP preservation\n  ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n  ##\n  externalTrafficPolicy: Cluster\n  ## @param service.annotations Annotations for Keycloak service\n  ##\n  annotations: {}\n## Ingress configuration\n##\ningress:\n  ## @param ingress.enabled Enable ingress controller resource\n  ##\n  enabled: false\n  ## DEPRECATED: Use ingress.annotations instead of ingress.certManager\n  ## certManager: false\n  ##\n\n  ## @param ingress.hostname Default host for the ingress resource\n  ##\n  hostname: keycloak.local\n  ## @param ingress.apiVersion Force Ingress API version (automatically detected if not set)\n  ##\n  apiVersion: \"\"\n  ## @param ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)\n  ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster\n  ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/\n  ##\n  ingressClassName: \"\"\n  ## @param ingress.path Ingress path\n  ##\n  path: /\n  ## @param ingress.pathType Ingress path type\n  ##\n  pathType: ImplementationSpecific\n  ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.\n  ## For a full list of possible ingress annotations, please see\n  ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md\n  ## Use this parameter to set the required annotations for cert-manager, see\n  ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations\n  ##\n  ## e.g:\n  ## annotations:\n  ##   kubernetes.io/ingress.class: nginx\n  ##   cert-manager.io/cluster-issuer: cluster-issuer-name\n  ##\n  annotations: {}\n  ## @param ingress.tls Enable TLS configuration for the hostname defined at `ingress.hostname` parameter\n  ## TLS certificates will be retrieved from a TLS secret with name: {{- printf \"%s-tls\" .Values.ingress.hostname }}\n  ## You can use the ingress.secrets parameter to create this TLS secret, relay on cert-manager to create it, or\n  ## let the chart create self-signed certificates for you\n  ##\n  tls: false\n  ## @param ingress.extraHosts The list of additional hostnames to be covered with this ingress record.\n  ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array\n  ## Example:\n  ## extraHosts:\n  ##   - name: keycloak.local\n  ##     path: /\n  ##\n  extraHosts: []\n  ## @param ingress.extraTls The tls configuration for additional hostnames to be covered with this ingress record.\n  ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls\n  ## Example:\n  ## extraTls:\n  ## - hosts:\n  ##     - keycloak.local\n  ##   secretName: keycloak.local-tls\n  ##\n  extraTls: []\n  ## @param ingress.secrets If you're providing your own certificates, please use this to add the certificates as secrets\n  ## key and certificate should start with -----BEGIN CERTIFICATE----- or -----BEGIN RSA PRIVATE KEY-----\n  ## name should line up with a secretName set further up\n  ##\n  ## If it is not set and you're using cert-manager, this is unneeded, as it will create the secret for you\n  ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created\n  ## It is also possible to create and manage the certificates outside of this helm chart\n  ## Please see README.md for more information\n  ##\n  ## Example\n  ## secrets:\n  ##   - name: aspnet-core.local-tls\n  ##     key: \"\"\n  ##     certificate: \"\"\n  ##\n  secrets: []\n  ## @param ingress.existingSecret It is you own the certificate as secret.\n  existingSecret: \"\"\n  ## @param ingress.servicePort Service port to be used\n  ## Default is http. Alternative is https.\n  ##\n  servicePort: https\n## Network Policy configuration\n## ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/\n##\nnetworkPolicy:\n  ## @param networkPolicy.enabled Enable the default NetworkPolicy policy\n  ##\n  enabled: false\n  ## @param networkPolicy.allowExternal Don't require client label for connections\n  ## The Policy model to apply. When set to false, only pods with the correct\n  ## client label will have network access to the ports Keycloak is listening\n  ## on. When true, Keycloak will accept connections from any source\n  ## (with the correct destination port).\n  ##\n  allowExternal: true\n  ## @param networkPolicy.additionalRules Additional NetworkPolicy rules\n  ## Note that all rules are OR-ed.\n  ## Example:\n  ## additionalRules:\n  ##   - matchLabels:\n  ##       - role: frontend\n  ##   - matchExpressions:\n  ##       - key: role\n  ##         operator: In\n  ##         values:\n  ##           - frontend\n  ##\n  additionalRules: {}\n\n## @section RBAC parameter\n## Specifies whether a ServiceAccount should be created\n##\nserviceAccount:\n  ## @param serviceAccount.create Enable the creation of a ServiceAccount for Keycloak pods\n  ##\n  create: true\n  ## @param serviceAccount.name Name of the created ServiceAccount\n  ## If not set and create is true, a name is generated using the fullname template\n  ##\n  name: \"\"\n  ## @param serviceAccount.automountServiceAccountToken Auto-mount the service account token in the pod\n  ##\n  automountServiceAccountToken: false\n## Specifies whether RBAC resources should be created\n##\nrbac:\n  ## @param rbac.create Whether to create and use RBAC resources or not\n  ##\n  create: false\n  ## @param rbac.rules Custom RBAC rules\n  ## Example:\n  ## rules:\n  ##   - apiGroups:\n  ##       - \"\"\n  ##     resources:\n  ##       - pods\n  ##     verbs:\n  ##       - get\n  ##       - list\n  ##\n  rules: []\n\n## @section Other parameters\n\n## Keycloak Pod Disruption Budget configuration\n## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n##\npdb:\n  ## @param pdb.create Enable/disable a Pod Disruption Budget creation\n  ##\n  create: false\n  ## @param pdb.minAvailable Minimum number/percentage of pods that should remain scheduled\n  ##\n  minAvailable: 1\n  ## @param pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable\n  ##\n  maxUnavailable: \"\"\n## Keycloak Autoscaling configuration\n## @param autoscaling.enabled Enable autoscaling for Keycloak\n## @param autoscaling.minReplicas Minimum number of Keycloak replicas\n## @param autoscaling.maxReplicas Maximum number of Keycloak replicas\n## @param autoscaling.targetCPU Target CPU utilization percentage\n## @param autoscaling.targetMemory Target Memory utilization percentage\n##\nautoscaling:\n  enabled: false\n  minReplicas: 1\n  maxReplicas: 11\n  targetCPU: \"\"\n  targetMemory: \"\"\n\n## @section Metrics parameters\n\n## Metrics configuration\n##\nmetrics:\n  ## @param metrics.enabled Enable exposing Keycloak statistics\n  ## ref: https://github.com/bitnami/bitnami-docker-keycloak#enabling-statistics\n  ##\n  enabled: false\n  ## Keycloak metrics service parameters\n  ##\n  service:\n    ## @param metrics.service.port Service HTTP management port\n    ##\n    port: 9990\n    ## @param metrics.service.annotations [object] Annotations for enabling prometheus to access the metrics endpoints\n    ##\n    annotations:\n      prometheus.io/scrape: \"true\"\n      prometheus.io/port: \"{{ .Values.metrics.service.port }}\"\n  ## Prometheus Operator ServiceMonitor configuration\n  ##\n  serviceMonitor:\n    ## @param metrics.serviceMonitor.enabled Create ServiceMonitor Resource for scraping metrics using PrometheusOperator\n    ##\n    enabled: false\n    ## @param metrics.serviceMonitor.namespace Namespace which Prometheus is running in\n    ##\n    namespace: \"\"\n    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped\n    ##\n    interval: 30s\n    ## @param metrics.serviceMonitor.scrapeTimeout Specify the timeout after which the scrape is ended\n    ## e.g:\n    ##   scrapeTimeout: 30s\n    ##\n    scrapeTimeout: \"\"\n    ## @param metrics.serviceMonitor.relabellings Specify Metric Relabellings to add to the scrape endpoint\n    ##\n    relabellings: []\n    ## @param metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels\n    ##\n    honorLabels: false\n    ## @param metrics.serviceMonitor.additionalLabels Used to pass Labels that are required by the installed Prometheus Operator\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec\n    ##\n    additionalLabels: {}\n\n## @section Database parameters\n\n## PostgreSQL chart configuration\n## ref: https://github.com/bitnami/charts/blob/master/bitnami/postgresql/values.yaml\n##\npostgresql:\n  ## @param postgresql.enabled Deploy a PostgreSQL server to satisfy the applications database requirements\n  ##\n  enabled: true\n  ## @param postgresql.postgresqlUsername Keycloak PostgreSQL user (has superuser privileges if username is `postgres`)\n  ## ref: https://github.com/bitnami/bitnami-docker-postgresql/blob/master/README.md#setting-the-root-password-on-first-run\n  ##\n  postgresqlUsername: bn_keycloak\n  ## @param postgresql.postgresqlPassword Keycloak PostgreSQL password - ignored if existingSecret is provided\n  ## Defaults to a random 10-character alphanumeric string if not set\n  ## ref: https://github.com/bitnami/bitnami-docker-postgresql/blob/master/README.md#setting-the-root-password-on-first-run\n  ##\n  postgresqlPassword: \"\"\n  ## @param postgresql.postgresqlDatabase Name of the database to create\n  ## ref: https://github.com/bitnami/bitnami-docker-postgresql/blob/master/README.md#creating-a-database-on-first-run\n  ##\n  postgresqlDatabase: bitnami_keycloak\n  ## @param postgresql.existingSecret Use an existing secret file with the PostgreSQL password\n  ##\n  existingSecret: \"\"\n  ## Enable persistence using Persistent Volume Claims\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes\n  ##\n  persistence:\n    ## @param postgresql.persistence.enabled Enable PostgreSQL persistence using PVC\n    ##\n    enabled: true\n## External database configuration\n##\nexternalDatabase:\n  ## @param externalDatabase.host Host of the external database\n  ##\n  host: \"\"\n  ## @param externalDatabase.port Database port\n  ##\n  port: 5432\n  ## @param externalDatabase.user non admin username for Keycloak Database\n  ##\n  user: bn_keycloak\n  ## @param externalDatabase.password Database password\n  ##\n  password: \"\"\n  ## @param externalDatabase.database Database name\n  ##\n  database: bitnami_keycloak\n  ## @param externalDatabase.existingSecret Use an existing secret file with the external PostgreSQL credentials\n  ##\n  existingSecret: \"\"\n"
            ],
            "verify": false,
            "version": "5.2.2",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "module.kube.kubernetes_namespace.ldap",
            "module.kube.kubernetes_namespace.mariadb",
            "module.kube.kubernetes_namespace.mlflow",
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub",
            "module.kube.kubernetes_namespace.keycloak"
          ]
        }
      ]
    },
    {
      "module": "module.kube",
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "istio_system",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "istio-system",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "istio-system",
                "resource_version": "47422",
                "uid": "c541fba5-1529-42f1-9d33-bb7166cc7b1b"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "module": "module.kube",
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "jupyterhub",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "jupyterhub",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {
                  "istio-injection": "enabled"
                },
                "name": "jupyterhub",
                "resource_version": "95199",
                "uid": "1109862d-d737-42be-9916-425fd8ffeb73"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "module": "module.kube",
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "keycloak",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "keycloak",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {
                  "istio-injection": "enabled"
                },
                "name": "keycloak",
                "resource_version": "47421",
                "uid": "006cddaa-c0df-4edb-82c6-2e16e2127683"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "module": "module.kube",
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "ldap",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "ldap",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {
                  "istio-injection": "enabled"
                },
                "name": "ldap",
                "resource_version": "47419",
                "uid": "266d9b19-7481-4a33-873d-16ade5dae444"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "module": "module.kube",
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "mariadb",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "mariadb",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {
                  "istio-injection": "enabled"
                },
                "name": "mariadb",
                "resource_version": "47418",
                "uid": "74c35a4f-beef-4bdd-8863-e5223ed0a095"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "module": "module.kube",
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "mlflow",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "mlflow",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {
                  "istio-injection": "enabled"
                },
                "name": "mlflow",
                "resource_version": "71428",
                "uid": "e38a011b-c9ea-46ac-9b18-effba12b8594"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "module": "module.ldap_install",
      "mode": "managed",
      "type": "helm_release",
      "name": "openldap",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "openldap-stack-ha",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "openldap",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "2.4.57",
                "chart": "openldap-stack-ha",
                "name": "openldap",
                "namespace": "ldap",
                "revision": 1,
                "values": "{\"adminPassword\":\"admin\",\"configPassword\":\"admin\",\"customFileSets\":[],\"customTLS\":{\"CA\":{\"enabled\":false},\"enabled\":false,\"secret\":\"\"},\"env\":{\"CONTAINER_LOG_LEVEL\":\"4\",\"KEEP_EXISTING_CONFIG\":\"false\",\"LDAP_BACKEND\":\"mdb\",\"LDAP_DOMAIN\":\"lakehouse.home\",\"LDAP_LOG_LEVEL\":\"256\",\"LDAP_ORGANISATION\":\"lakehouse\",\"LDAP_READONLY_USER\":\"false\",\"LDAP_READONLY_USER_PASSWORD\":\"readonly\",\"LDAP_READONLY_USER_USERNAME\":\"readonly\",\"LDAP_REMOVE_CONFIG_AFTER_SETUP\":\"true\",\"LDAP_RFC2307BIS_SCHEMA\":\"false\",\"LDAP_SSL_HELPER_PREFIX\":\"ldap\",\"LDAP_TLS\":\"true\",\"LDAP_TLS_CA_CRT_FILENAME\":\"ca.crt\",\"LDAP_TLS_CIPHER_SUITE\":\"NORMAL\",\"LDAP_TLS_CRT_FILENAME\":\"tls.crt\",\"LDAP_TLS_DH_PARAM_FILENAME\":\"dhparam.pem\",\"LDAP_TLS_ENFORCE\":\"false\",\"LDAP_TLS_KEY_FILENAME\":\"tls.key\",\"LDAP_TLS_PROTOCOL_MIN\":\"3.0\",\"LDAP_TLS_REQCERT\":\"never\",\"LDAP_TLS_VERIFY_CLIENT\":\"never\"},\"existingSecret\":\"\",\"extraLabels\":{},\"extraVolumeMounts\":null,\"extraVolumes\":null,\"image\":{\"pullPolicy\":\"Always\",\"repository\":\"osixia/openldap\",\"tag\":\"1.5.0\"},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":10,\"initialDelaySeconds\":20,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"logLevel\":\"info\",\"ltb-passwd\":{\"enabled\":true,\"ingress\":{\"enabled\":false},\"ldap\":{\"bindDN\":\"cn=admin,dc=lakehouse,dc=fr\",\"bindPWKey\":\"LDAP_ADMIN_PASSWORD\",\"searchBase\":\"dc=lakehouse,dc=fr\",\"server\":\"ldap://openldap-openldap-stack-ha\"}},\"nodeSelector\":{},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"enabled\":true,\"size\":\"8Gi\"},\"phpldapadmin\":{\"enabled\":true,\"env\":{\"PHPLDAPADMIN_LDAP_HOSTS\":\"openldap-openldap-stack-ha\"},\"ingress\":{\"enabled\":false}},\"podAnnotations\":{},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":10,\"initialDelaySeconds\":20,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicaCount\":1,\"replication\":{\"clusterName\":\"cluster.local\",\"enabled\":true,\"interval\":\"00:00:00:10\",\"retry\":60,\"starttls\":\"critical\",\"timeout\":1,\"tls_reqcert\":\"never\"},\"resources\":{},\"service\":{\"annotations\":{},\"externalIPs\":[],\"ldapPort\":389,\"sessionAffinity\":\"None\",\"sslLdapPort\":636,\"type\":\"ClusterIP\"},\"startupProbe\":{\"enabled\":false,\"failureThreshold\":30,\"initialDelaySeconds\":0,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"test\":{\"enabled\":false,\"image\":{\"repository\":\"dduportal/bats\",\"tag\":\"0.4.0\"}},\"tolerations\":[],\"updateStrategy\":{}}",
                "version": "2.1.6"
              }
            ],
            "name": "openldap",
            "namespace": "ldap",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://jp-gouin.github.io/helm-openldap",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 1000,
            "values": [
              "# Default values for openldap.\n# This is a YAML-formatted file.\n# Declare variables to be passed into your templates.\n\nreplicaCount: 1\nupdateStrategy: {}\n  # When a StatefulSet's .spec.updateStrategy.type is set to OnDelete, \n  # the StatefulSet controller will not automatically update the Pods\n  # in a StatefulSet. Users must manually delete Pods to cause the\n  # controller to create new Pods that reflect modifications made\n  # to a StatefulSet's .spec.template.\n  # \n  # type: OnDelete\n  # \n  # or\n  # \n  # When a StatefulSet's .spec.updateStrategy.type is set to RollingUpdate,\n  # the StatefulSet controller will delete and recreate each Pod in the StatefulSet.\n  # It will proceed in the same order as Pod termination (from the largest ordinal \n  # to the smallest), updating each Pod one at a time. It will wait until an updated\n  # Pod is Running and Ready prior to updating its predecessor.\n  # \n  # type: RollingUpdate\n  # rollingUpdate:\n  #   partition: 1\nimage:\n  # From repository https://github.com/osixia/docker-openldap\n  repository: osixia/openldap\n  tag: 1.5.0\n  pullPolicy: Always\n  # pullSecret: harbor\n\n# Set the container log level\n# Valid log levels: none, error, warning, info (default), debug, trace\nlogLevel: info\n\n# Specifies an existing secret to be used for admin and config user passwords\nexistingSecret: \"\"\n\n# Settings for enabling TLS with custom certificate\n# need a secret with tls.crt, tls.key and ca.crt keys with associated files\n# Ref: https://kubernetes.io/docs/tasks/configmap-secret/managing-secret-using-kubectl/#create-a-secret\ncustomTLS:\n  enabled: false\n  secret: \"\"  # The name of a kubernetes.io/tls type secret to use for TLS\n  CA:\n    enabled: false\n## Add additional labels to all resources\nextraLabels: {}\n## Add additional annotations to pods\npodAnnotations: {}\nservice:\n  annotations: {}\n\n  ldapPort: 389\n  sslLdapPort: 636\n\n  ## If service type NodePort, define the value here\n  #ldapPortNodePort:\n  #sslLdapPortNodePort:\n  ## List of IP addresses at which the service is available\n  ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n  ##\n  externalIPs: []\n\n  #loadBalancerIP: \n  #loadBalancerSourceRanges: []\n  type: ClusterIP\n  sessionAffinity: None\n\n# Additional volumes to be mounted to pod\nextraVolumes:\n  # - name: ca-certs\n  #   hostPath:\n  #     path: /etc/ssl/certs/ca-bundle.crt\n  #     type: File\n\nextraVolumeMounts:\n  #- name: ca-certs\n  #  readOnly: true\n  #  mountPath: \"/etc/ssl/certs/ca-certificates.crt\"\n\n# Default configuration for openldap as environment variables. These get injected directly in the container.\n# Use the env variables from https://github.com/osixia/docker-openldap#beginner-guide\nenv:\n LDAP_LOG_LEVEL: \"256\"\n LDAP_ORGANISATION: \"lakehouse\"\n LDAP_DOMAIN: \"lakehouse.home\"\n LDAP_READONLY_USER: \"false\"\n LDAP_READONLY_USER_USERNAME: \"readonly\"\n LDAP_READONLY_USER_PASSWORD: \"readonly\"\n LDAP_RFC2307BIS_SCHEMA: \"false\"\n LDAP_BACKEND: \"mdb\"\n LDAP_TLS: \"true\"\n LDAP_TLS_CRT_FILENAME: \"tls.crt\"\n LDAP_TLS_KEY_FILENAME: \"tls.key\"\n LDAP_TLS_DH_PARAM_FILENAME: \"dhparam.pem\"\n LDAP_TLS_CA_CRT_FILENAME: \"ca.crt\"\n LDAP_TLS_ENFORCE: \"false\"\n CONTAINER_LOG_LEVEL: \"4\"\n LDAP_TLS_REQCERT: \"never\"\n KEEP_EXISTING_CONFIG: \"false\"\n LDAP_REMOVE_CONFIG_AFTER_SETUP: \"true\"\n LDAP_SSL_HELPER_PREFIX: \"ldap\"\n LDAP_TLS_VERIFY_CLIENT: \"never\"\n LDAP_TLS_PROTOCOL_MIN: \"3.0\"\n LDAP_TLS_CIPHER_SUITE: \"NORMAL\"\n\n  \n\n# Default Passwords to use, stored as a secret.\n# You can override these at install time with\n# helm install openldap --set openldap.adminPassword=\u003cpasswd\u003e,openldap.configPassword=\u003cpasswd\u003e\nadminPassword: admin\nconfigPassword: admin\n\n# Custom openldap configuration files used to override default settings\n# customLdifFiles:\n  # 01-default-users.ldif: |-\n    # Predefine users here\n\n# Custom files with provided contents to be added in container.\ncustomFileSets: []\n#- name: fileset1\n#  targetPath: /container/service/slapd/assets/config/bootstrap/ldif\n#  files:\n#  - filename: 03-memberOf.ldif\n#    content: |\n#      dn: cn=module{0},cn=config\n#      changetype: modify\n#      add: olcModuleLoad\n#      olcModuleLoad: memberof\n\nreplication:\n  enabled: true    \n  # Enter the name of your cluster, defaults to \"cluster.local\"\n  clusterName: \"cluster.local\"\n  retry: 60\n  timeout: 1\n  interval: 00:00:00:10\n  starttls: \"critical\"\n  tls_reqcert: \"never\"\n## Persist data to a persistent volume\npersistence:\n  enabled: true\n  ## database data Persistent Volume Storage Class\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS \u0026 OpenStack)\n  ##\n  # storageClass: \"standard-singlewriter\"\n  # existingClaim: openldap-pvc\n  accessModes:\n    - ReadWriteOnce\n  size: 8Gi\n\nlivenessProbe:\n  enabled: true\n  initialDelaySeconds: 20\n  periodSeconds: 10\n  timeoutSeconds: 1\n  successThreshold: 1\n  failureThreshold: 10\nreadinessProbe:\n  enabled: true\n  initialDelaySeconds: 20\n  periodSeconds: 10\n  timeoutSeconds: 1\n  successThreshold: 1\n  failureThreshold: 10\nstartupProbe:\n  enabled: false\n  initialDelaySeconds: 0\n  periodSeconds: 10\n  timeoutSeconds: 1\n  successThreshold: 1\n  failureThreshold: 30\n\nresources: {}\n\nnodeSelector: {}\n\ntolerations: []\n\ntest:\n  enabled: false\n  image:\n    repository: dduportal/bats\n    tag: 0.4.0\nltb-passwd:\n  enabled : true\n  ingress:\n    enabled: false\n  ldap:\n    server: ldap://openldap-openldap-stack-ha\n    searchBase: dc=lakehouse,dc=fr\n    bindDN: cn=admin,dc=lakehouse,dc=fr\n    bindPWKey: LDAP_ADMIN_PASSWORD\n\nphpldapadmin:\n  enabled: true\n  ingress:\n    enabled: false\n  env:\n    PHPLDAPADMIN_LDAP_HOSTS: openldap-openldap-stack-ha"
            ],
            "verify": false,
            "version": "2.1.6",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "module.kube.kubernetes_namespace.mariadb",
            "module.kube.kubernetes_namespace.mlflow",
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub",
            "module.kube.kubernetes_namespace.keycloak",
            "module.kube.kubernetes_namespace.ldap"
          ]
        }
      ]
    },
    {
      "module": "module.mariadb_install",
      "mode": "managed",
      "type": "helm_release",
      "name": "mariadb",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "mariadb",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "mariadb",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "10.5.13",
                "chart": "mariadb",
                "name": "mariadb",
                "namespace": "mariadb",
                "revision": 1,
                "values": "{\"architecture\":\"standalone\",\"auth\":{\"customPasswordFiles\":{},\"database\":\"my_database\",\"existingSecret\":\"\",\"forcePassword\":false,\"password\":\"\",\"replicationPassword\":\"\",\"replicationUser\":\"replicator\",\"rootPassword\":\"admin\",\"usePasswordFiles\":false,\"username\":\"\"},\"clusterDomain\":\"cluster.local\",\"commonAnnotations\":{},\"commonLabels\":{},\"diagnosticMode\":{\"args\":[\"infinity\"],\"command\":[\"sleep\"],\"enabled\":false},\"extraDeploy\":[],\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"storageClass\":\"\"},\"image\":{\"debug\":false,\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/mariadb\",\"tag\":\"10.5.13-debian-10-r32\"},\"initdbScripts\":{},\"initdbScriptsConfigMap\":\"\",\"kubeVersion\":\"\",\"metrics\":{\"annotations\":{\"prometheus.io/port\":\"9104\",\"prometheus.io/scrape\":\"true\"},\"containerSecurityContext\":{\"enabled\":false},\"enabled\":false,\"extraArgs\":{\"primary\":[],\"secondary\":[]},\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/mysqld-exporter\",\"tag\":\"0.13.0-debian-10-r183\"},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":120,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{\"limits\":{},\"requests\":{}},\"serviceMonitor\":{\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"jobLabel\":\"\",\"labels\":{},\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scrapeTimeout\":\"\",\"selector\":{}}},\"nameOverride\":\"\",\"networkPolicy\":{\"egressRules\":{\"customRules\":{},\"denyConnectionsToExternal\":false},\"enabled\":false,\"ingressRules\":{\"primaryAccessOnlyFrom\":{\"customRules\":{},\"enabled\":false,\"namespaceSelector\":{},\"podSelector\":{}},\"secondaryAccessOnlyFrom\":{\"customRules\":{},\"enabled\":false,\"namespaceSelector\":{},\"podSelector\":{}}},\"metrics\":{\"enabled\":false,\"namespaceSelector\":{},\"podSelector\":{}}},\"primary\":{\"affinity\":{},\"args\":[],\"command\":[],\"configuration\":\"[mysqld]\\nskip-name-resolve\\nexplicit_defaults_for_timestamp\\nbasedir=/opt/bitnami/mariadb\\nplugin_dir=/opt/bitnami/mariadb/plugin\\nport=3306\\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\\ntmpdir=/opt/bitnami/mariadb/tmp\\nmax_allowed_packet=16M\\nbind-address=::\\npid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\\nlog-error=/opt/bitnami/mariadb/logs/mysqld.log\\ncharacter-set-server=UTF8\\ncollation-server=utf8_general_ci\\n\\n[client]\\nport=3306\\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\\ndefault-character-set=UTF8\\nplugin_dir=/opt/bitnami/mariadb/plugin\\n\\n[manager]\\nport=3306\\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\\npid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\",\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"existingConfigmap\":\"\",\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraFlags\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"initContainers\":[],\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":120,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"pdb\":{\"create\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":true,\"existingClaim\":\"\",\"selector\":{},\"size\":\"8Gi\",\"storageClass\":\"\",\"subPath\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podManagementPolicy\":\"\",\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{\"limits\":{},\"requests\":{}},\"revisionHistoryLimit\":10,\"rollingUpdatePartition\":\"\",\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"externalTrafficPolicy\":\"Cluster\",\"extraPorts\":[],\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"mysql\":\"\"},\"ports\":{\"mysql\":3306},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"sidecars\":[],\"startupProbe\":{\"enabled\":false,\"failureThreshold\":10,\"initialDelaySeconds\":120,\"periodSeconds\":15,\"successThreshold\":1,\"timeoutSeconds\":5},\"startupWaitOptions\":{},\"tolerations\":[],\"topologySpreadConstraints\":{},\"updateStrategy\":{\"type\":\"RollingUpdate\"}},\"rbac\":{\"create\":false},\"schedulerName\":\"\",\"secondary\":{\"affinity\":{},\"args\":[],\"command\":[],\"configuration\":\"[mysqld]\\nskip-name-resolve\\nexplicit_defaults_for_timestamp\\nbasedir=/opt/bitnami/mariadb\\nport=3306\\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\\ntmpdir=/opt/bitnami/mariadb/tmp\\nmax_allowed_packet=16M\\nbind-address=0.0.0.0\\npid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\\nlog-error=/opt/bitnami/mariadb/logs/mysqld.log\\ncharacter-set-server=UTF8\\ncollation-server=utf8_general_ci\\n\\n[client]\\nport=3306\\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\\ndefault-character-set=UTF8\\n\\n[manager]\\nport=3306\\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\\npid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\",\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"existingConfigmap\":\"\",\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraFlags\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"initContainers\":[],\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":120,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"pdb\":{\"create\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":true,\"selector\":{},\"size\":\"8Gi\",\"storageClass\":\"\",\"subPath\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podManagementPolicy\":\"\",\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicaCount\":1,\"resources\":{\"limits\":{},\"requests\":{}},\"revisionHistoryLimit\":10,\"rollingUpdatePartition\":\"\",\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"externalTrafficPolicy\":\"Cluster\",\"extraPorts\":[],\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"mysql\":\"\"},\"ports\":{\"mysql\":3306},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"sidecars\":[],\"startupProbe\":{\"enabled\":false,\"failureThreshold\":10,\"initialDelaySeconds\":120,\"periodSeconds\":15,\"successThreshold\":1,\"timeoutSeconds\":5},\"startupWaitOptions\":{},\"tolerations\":[],\"topologySpreadConstraints\":{},\"updateStrategy\":{\"type\":\"RollingUpdate\"}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":false,\"create\":true,\"name\":\"\"},\"volumePermissions\":{\"enabled\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/bitnami-shell\",\"tag\":\"10-debian-10-r279\"},\"resources\":{\"limits\":{},\"requests\":{}}}}",
                "version": "10.1.1"
              }
            ],
            "name": "mariadb",
            "namespace": "mariadb",
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://charts.bitnami.com/bitnami",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 1000,
            "values": [
              "## @section Global parameters\n## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass\n\n## @param global.imageRegistry Global Docker Image registry\n## @param global.imagePullSecrets Global Docker registry secret names as an array\n## @param global.storageClass Global storage class for dynamic provisioning\n##\nglobal:\n  imageRegistry: \"\"\n  ## E.g.\n  ## imagePullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  imagePullSecrets: []\n  storageClass: \"\"\n\n## @section Common parameters\n\n## @param kubeVersion Force target Kubernetes version (using Helm capabilities if not set)\n##\nkubeVersion: \"\"\n## @param nameOverride String to partially override mariadb.fullname\n##\nnameOverride: \"\"\n## @param fullnameOverride String to fully override mariadb.fullname\n##\nfullnameOverride: \"\"\n## @param clusterDomain Default Kubernetes cluster domain\n##\nclusterDomain: cluster.local\n## @param commonAnnotations Common annotations to add to all MariaDB resources (sub-charts are not considered)\n##\ncommonAnnotations: {}\n## @param commonLabels Common labels to add to all MariaDB resources (sub-charts are not considered)\n##\ncommonLabels: {}\n## @param schedulerName Name of the scheduler (other than default) to dispatch pods\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\nschedulerName: \"\"\n## @param extraDeploy Array of extra objects to deploy with the release (evaluated as a template)\n##\nextraDeploy: []\n\n## Enable diagnostic mode in the deployment\n##\ndiagnosticMode:\n  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)\n  ##\n  enabled: false\n  ## @param diagnosticMode.command Command to override all containers in the deployment\n  ##\n  command:\n    - sleep\n  ## @param diagnosticMode.args Args to override all containers in the deployment\n  ##\n  args:\n    - infinity\n\n## @section MariaDB common parameters\n\n## Bitnami MariaDB image\n## ref: https://hub.docker.com/r/bitnami/mariadb/tags/\n## @param image.registry MariaDB image registry\n## @param image.repository MariaDB image repository\n## @param image.tag MariaDB image tag (immutable tags are recommended)\n## @param image.pullPolicy MariaDB image pull policy\n## @param image.pullSecrets Specify docker-registry secret names as an array\n## @param image.debug Specify if debug logs should be enabled\n##\nimage:\n  registry: docker.io\n  repository: bitnami/mariadb\n  tag: 10.5.13-debian-10-r32\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ## Example:\n  ## pullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  pullSecrets: []\n  ## Set to true if you would like to see extra information on logs\n  ## It turns BASH and/or NAMI debugging in the image\n  ##\n  debug: false\n## @param architecture MariaDB architecture (`standalone` or `replication`)\n##\narchitecture: standalone\n## MariaDB Authentication parameters\n##\nauth:\n  ## @param auth.rootPassword Password for the `root` user. Ignored if existing secret is provided.\n  ## ref: https://github.com/bitnami/bitnami-docker-mariadb#setting-the-root-password-on-first-run\n  ##\n  rootPassword: \"admin\"\n  ## @param auth.database Name for a custom database to create\n  ## ref: https://github.com/bitnami/bitnami-docker-mariadb/blob/master/README.md#creating-a-database-on-first-run\n  ##\n  database: my_database\n  ## @param auth.username Name for a custom user to create\n  ## ref: https://github.com/bitnami/bitnami-docker-mariadb/blob/master/README.md#creating-a-database-user-on-first-run\n  ##\n  username: \"\"\n  ## @param auth.password Password for the new user. Ignored if existing secret is provided\n  ##\n  password: \"\"\n  ## @param auth.replicationUser MariaDB replication user\n  ## ref: https://github.com/bitnami/bitnami-docker-mariadb#setting-up-a-replication-cluster\n  ##\n  replicationUser: replicator\n  ## @param auth.replicationPassword MariaDB replication user password. Ignored if existing secret is provided\n  ## ref: https://github.com/bitnami/bitnami-docker-mariadb#setting-up-a-replication-cluster\n  ##\n  replicationPassword: \"\"\n  ## @param auth.existingSecret Use existing secret for password details (`auth.rootPassword`, `auth.password`, `auth.replicationPassword` will be ignored and picked up from this secret). The secret has to contain the keys `mariadb-root-password`, `mariadb-replication-password` and `mariadb-password`\n  ##\n  existingSecret: \"\"\n  ## @param auth.forcePassword Force users to specify required passwords\n  ##\n  forcePassword: false\n  ## @param auth.usePasswordFiles Mount credentials as a files instead of using an environment variable\n  ##\n  usePasswordFiles: false\n  ## @param auth.customPasswordFiles Use custom password files when `auth.usePasswordFiles` is set to `true`. Define path for keys `root` and `user`, also define `replicator` if `architecture` is set to `replication`\n  ## Example:\n  ## customPasswordFiles:\n  ##   root: /vault/secrets/mariadb-root\n  ##   user: /vault/secrets/mariadb-user\n  ##   replicator: /vault/secrets/mariadb-replicator\n  ##\n  customPasswordFiles: {}\n## @param initdbScripts Dictionary of initdb scripts\n## Specify dictionary of scripts to be run at first boot\n## Example:\n## initdbScripts:\n##   my_init_script.sh: |\n##      #!/bin/bash\n##      echo \"Do something.\"\n##\ninitdbScripts: {}\n## @param initdbScriptsConfigMap ConfigMap with the initdb scripts (Note: Overrides `initdbScripts`)\n##\ninitdbScriptsConfigMap: \"\"\n\n## @section MariaDB Primary parameters\n\n## Mariadb Primary parameters\n##\nprimary:\n  ## @param primary.command Override default container command on MariaDB Primary container(s) (useful when using custom images)\n  ##\n  command: []\n  ## @param primary.args Override default container args on MariaDB Primary container(s) (useful when using custom images)\n  ##\n  args: []\n  ## @param primary.lifecycleHooks for the MariaDB Primary container(s) to automate configuration before or after startup\n  ##\n  lifecycleHooks: {}\n  ## @param primary.hostAliases Add deployment host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## @param primary.configuration [string] MariaDB Primary configuration to be injected as ConfigMap\n  ## ref: https://mysql.com/kb/en/mysql/configuring-mysql-with-mycnf/#example-of-configuration-file\n  ##\n  configuration: |-\n    [mysqld]\n    skip-name-resolve\n    explicit_defaults_for_timestamp\n    basedir=/opt/bitnami/mariadb\n    plugin_dir=/opt/bitnami/mariadb/plugin\n    port=3306\n    socket=/opt/bitnami/mariadb/tmp/mysql.sock\n    tmpdir=/opt/bitnami/mariadb/tmp\n    max_allowed_packet=16M\n    bind-address=::\n    pid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\n    log-error=/opt/bitnami/mariadb/logs/mysqld.log\n    character-set-server=UTF8\n    collation-server=utf8_general_ci\n\n    [client]\n    port=3306\n    socket=/opt/bitnami/mariadb/tmp/mysql.sock\n    default-character-set=UTF8\n    plugin_dir=/opt/bitnami/mariadb/plugin\n\n    [manager]\n    port=3306\n    socket=/opt/bitnami/mariadb/tmp/mysql.sock\n    pid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\n  ## @param primary.existingConfigmap Name of existing ConfigMap with MariaDB Primary configuration.\n  ## NOTE: When it's set the 'configuration' parameter is ignored\n  ##\n  existingConfigmap: \"\"\n  ## @param primary.updateStrategy.type MariaDB primary statefulset strategy type\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n  ##\n  updateStrategy:\n    ## StrategyType\n    ## Can be set to RollingUpdate or OnDelete\n    ##\n    type: RollingUpdate\n  ## @param primary.rollingUpdatePartition Partition update strategy for Mariadb Primary statefulset\n  ## https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#partitions\n  ##\n  rollingUpdatePartition: \"\"\n  ## @param primary.podAnnotations Additional pod annotations for MariaDB primary pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param primary.podLabels Extra labels for MariaDB primary pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n  ##\n  podLabels: {}\n  ## @param primary.podAffinityPreset MariaDB primary pod affinity preset. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAffinityPreset: \"\"\n  ## @param primary.podAntiAffinityPreset MariaDB primary pod anti-affinity preset. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAntiAffinityPreset: soft\n  ## Mariadb Primary node affinity preset\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ##\n  nodeAffinityPreset:\n    ## @param primary.nodeAffinityPreset.type MariaDB primary node affinity preset type. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n    ##\n    type: \"\"\n    ## @param primary.nodeAffinityPreset.key MariaDB primary node label key to match Ignored if `primary.affinity` is set.\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## @param primary.nodeAffinityPreset.values MariaDB primary node label values to match. Ignored if `primary.affinity` is set.\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param primary.affinity Affinity for MariaDB primary pods assignment\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set\n  ##\n  affinity: {}\n  ## @param primary.nodeSelector Node labels for MariaDB primary pods assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param primary.tolerations Tolerations for MariaDB primary pods assignment\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param primary.schedulerName Name of the k8s scheduler (other than default)\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  schedulerName: \"\"\n  ## @param primary.podManagementPolicy podManagementPolicy to manage scaling operation of MariaDB primary pods\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies\n  ##\n  podManagementPolicy: \"\"\n  ## @param primary.topologySpreadConstraints Topology Spread Constraints for MariaDB primary pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## E.g.\n  ## topologySpreadConstraints:\n  ##   - maxSkew: 1\n  ##     topologyKey: topology.kubernetes.io/zone\n  ##     whenUnsatisfiable: DoNotSchedule\n  ##\n  topologySpreadConstraints: {}\n  ## @param primary.priorityClassName Priority class for MariaDB primary pods assignment\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n  ##\n  priorityClassName: \"\"\n  ## MariaDB primary Pod security context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param primary.podSecurityContext.enabled Enable security context for MariaDB primary pods\n  ## @param primary.podSecurityContext.fsGroup Group ID for the mounted volumes' filesystem\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## MariaDB primary container security context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param primary.containerSecurityContext.enabled MariaDB primary container securityContext\n  ## @param primary.containerSecurityContext.runAsUser User ID for the MariaDB primary container\n  ## @param primary.containerSecurityContext.runAsNonRoot Set Controller container's Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## MariaDB primary container's resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param primary.resources.limits The resources limits for MariaDB primary containers\n  ## @param primary.resources.requests The requested resources for MariaDB primary containers\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 100m\n    ##    memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 100m\n    ##    memory: 256Mi\n    requests: {}\n  ## Configure extra options for MariaDB primary containers' liveness, readiness and startup probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes)\n  ## @param primary.startupProbe.enabled Enable startupProbe\n  ## @param primary.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param primary.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param primary.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param primary.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param primary.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: false\n    initialDelaySeconds: 120\n    periodSeconds: 15\n    timeoutSeconds: 5\n    failureThreshold: 10\n    successThreshold: 1\n  ## Configure extra options for liveness probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param primary.livenessProbe.enabled Enable livenessProbe\n  ## @param primary.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param primary.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param primary.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param primary.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param primary.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 120\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 3\n    successThreshold: 1\n  ## @param primary.readinessProbe.enabled Enable readinessProbe\n  ## @param primary.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param primary.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param primary.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param primary.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param primary.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 3\n    successThreshold: 1\n  ## @param primary.customStartupProbe Override default startup probe for MariaDB primary containers\n  ##\n  customStartupProbe: {}\n  ## @param primary.customLivenessProbe Override default liveness probe for MariaDB primary containers\n  ##\n  customLivenessProbe: {}\n  ## @param primary.customReadinessProbe Override default readiness probe for MariaDB primary containers\n  ##\n  customReadinessProbe: {}\n  ## @param primary.startupWaitOptions Override default builtin startup wait check options for MariaDB primary containers\n  ## `bitnami/mariadb` Docker image has built-in startup check mechanism,\n  ## which periodically checks if MariaDB service has started up and stops it\n  ## if all checks have failed after X tries. Use these to control these checks.\n  ## ref: https://github.com/bitnami/bitnami-docker-mariadb/pull/240\n  ## Example (with default options):\n  ## startupWaitOptions:\n  ##   retries: 300\n  ##   waitTime: 2\n  ##\n  startupWaitOptions: {}\n  ## @param primary.extraFlags MariaDB primary additional command line flags\n  ## Can be used to specify command line flags, for example:\n  ## E.g.\n  ## extraFlags: \"--max-connect-errors=1000 --max_connections=155\"\n  ##\n  extraFlags: \"\"\n  ## @param primary.extraEnvVars Extra environment variables to be set on MariaDB primary containers\n  ## E.g.\n  ## extraEnvVars:\n  ##  - name: TZ\n  ##    value: \"Europe/Paris\"\n  ##\n  extraEnvVars: []\n  ## @param primary.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for MariaDB primary containers\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param primary.extraEnvVarsSecret Name of existing Secret containing extra env vars for MariaDB primary containers\n  ##\n  extraEnvVarsSecret: \"\"\n  ## Enable persistence using Persistent Volume Claims\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/\n  ##\n  persistence:\n    ## @param primary.persistence.enabled Enable persistence on MariaDB primary replicas using a `PersistentVolumeClaim`. If false, use emptyDir\n    ##\n    enabled: true\n    ## @param primary.persistence.existingClaim Name of an existing `PersistentVolumeClaim` for MariaDB primary replicas\n    ## NOTE: When it's set the rest of persistence parameters are ignored\n    ##\n    existingClaim: \"\"\n    ## @param primary.persistence.subPath Subdirectory of the volume to mount at\n    ##\n    subPath: \"\"\n    ## @param primary.persistence.storageClass MariaDB primary persistent volume storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    storageClass: \"\"\n    ## @param primary.persistence.annotations MariaDB primary persistent volume claim annotations\n    ##\n    annotations: {}\n    ## @param primary.persistence.accessModes MariaDB primary persistent volume access Modes\n    ##\n    accessModes:\n      - ReadWriteOnce\n    ## @param primary.persistence.size MariaDB primary persistent volume size\n    ##\n    size: 8Gi\n    ## @param primary.persistence.selector Selector to match an existing Persistent Volume\n    ## selector:\n    ##   matchLabels:\n    ##     app: my-app\n    ##\n    selector: {}\n  ## @param primary.extraVolumes Optionally specify extra list of additional volumes to the MariaDB Primary pod(s)\n  ##\n  extraVolumes: []\n  ## @param primary.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the MariaDB Primary container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param primary.initContainers Add additional init containers for the MariaDB Primary pod(s)\n  ##\n  initContainers: []\n  ## @param primary.sidecars Add additional sidecar containers for the MariaDB Primary pod(s)\n  ##\n  sidecars: []\n  ## MariaDB Primary Service parameters\n  ##\n  service:\n    ## @param primary.service.type MariaDB Primary Kubernetes service type\n    ##\n    type: ClusterIP\n    ## @param primary.service.ports.mysql MariaDB Primary Kubernetes service port\n    ##\n    ports:\n      mysql: 3306\n    ## @param primary.service.nodePorts.mysql MariaDB Primary Kubernetes service node port\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n    ##\n    nodePorts:\n      mysql: \"\"\n    ## @param primary.service.clusterIP MariaDB Primary Kubernetes service clusterIP IP\n    ##\n    clusterIP: \"\"\n    ## @param primary.service.loadBalancerIP MariaDB Primary loadBalancerIP if service type is `LoadBalancer`\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n    ##\n    loadBalancerIP: \"\"\n    ## @param primary.service.externalTrafficPolicy Enable client source IP preservation\n    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n    ##\n    externalTrafficPolicy: Cluster\n    ## @param primary.service.loadBalancerSourceRanges Address that are allowed when MariaDB Primary service is LoadBalancer\n    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n    ## E.g.\n    ## loadBalancerSourceRanges:\n    ##   - 10.10.10.0/24\n    ##\n    loadBalancerSourceRanges: []\n    ## @param primary.service.extraPorts Extra ports to expose (normally used with the `sidecar` value)\n    ##\n    extraPorts: []\n    ## @param primary.service.annotations Provide any additional annotations which may be required\n    ##\n    annotations: {}\n    ## @param primary.service.sessionAffinity Session Affinity for Kubernetes service, can be \"None\" or \"ClientIP\"\n    ## If \"ClientIP\", consecutive client requests will be directed to the same Pod\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies\n    ##\n    sessionAffinity: None\n    ## @param primary.service.sessionAffinityConfig Additional settings for the sessionAffinity\n    ## sessionAffinityConfig:\n    ##   clientIP:\n    ##     timeoutSeconds: 300\n    sessionAffinityConfig: {}\n  ## MariaDB primary Pod Disruption Budget configuration\n  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  ##\n  pdb:\n    ## @param primary.pdb.create Enable/disable a Pod Disruption Budget creation for MariaDB primary pods\n    ##\n    create: false\n    ## @param primary.pdb.minAvailable Minimum number/percentage of MariaDB primary pods that must still be available after the eviction\n    ##\n    minAvailable: 1\n    ## @param primary.pdb.maxUnavailable Maximum number/percentage of MariaDB primary pods that can be unavailable after the eviction\n    ##\n    maxUnavailable: \"\"\n  ## @param primary.revisionHistoryLimit Maximum number of revisions that will be maintained in the StatefulSet\n  ##\n  revisionHistoryLimit: 10\n\n## @section MariaDB Secondary parameters\n\n## Mariadb Secondary parameters\n##\nsecondary:\n  ## @param secondary.replicaCount Number of MariaDB secondary replicas\n  ##\n  replicaCount: 1\n  ## @param secondary.command Override default container command on MariaDB Secondary container(s) (useful when using custom images)\n  ##\n  command: []\n  ## @param secondary.args Override default container args on MariaDB Secondary container(s) (useful when using custom images)\n  ##\n  args: []\n  ## @param secondary.lifecycleHooks for the MariaDB Secondary container(s) to automate configuration before or after startup\n  ##\n  lifecycleHooks: {}\n  ## @param secondary.hostAliases Add deployment host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## @param secondary.configuration [string] MariaDB Secondary configuration to be injected as ConfigMap\n  ## ref: https://mysql.com/kb/en/mysql/configuring-mysql-with-mycnf/#example-of-configuration-file\n  ##\n  configuration: |-\n    [mysqld]\n    skip-name-resolve\n    explicit_defaults_for_timestamp\n    basedir=/opt/bitnami/mariadb\n    port=3306\n    socket=/opt/bitnami/mariadb/tmp/mysql.sock\n    tmpdir=/opt/bitnami/mariadb/tmp\n    max_allowed_packet=16M\n    bind-address=0.0.0.0\n    pid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\n    log-error=/opt/bitnami/mariadb/logs/mysqld.log\n    character-set-server=UTF8\n    collation-server=utf8_general_ci\n\n    [client]\n    port=3306\n    socket=/opt/bitnami/mariadb/tmp/mysql.sock\n    default-character-set=UTF8\n\n    [manager]\n    port=3306\n    socket=/opt/bitnami/mariadb/tmp/mysql.sock\n    pid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\n  ## @param secondary.existingConfigmap Name of existing ConfigMap with MariaDB Secondary configuration.\n  ## NOTE: When it's set the 'configuration' parameter is ignored\n  ##\n  existingConfigmap: \"\"\n  ## @param secondary.updateStrategy.type MariaDB secondary statefulset strategy type\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n  ##\n  updateStrategy:\n    ## StrategyType\n    ## Can be set to RollingUpdate or OnDelete\n    ##\n    type: RollingUpdate\n  ## @param secondary.rollingUpdatePartition Partition update strategy for Mariadb Secondary statefulset\n  ## https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#partitions\n  ##\n  rollingUpdatePartition: \"\"\n  ## @param secondary.podAnnotations Additional pod annotations for MariaDB secondary pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param secondary.podLabels Extra labels for MariaDB secondary pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n  ##\n  podLabels: {}\n  ## @param secondary.podAffinityPreset MariaDB secondary pod affinity preset. Ignored if `secondary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAffinityPreset: \"\"\n  ## @param secondary.podAntiAffinityPreset MariaDB secondary pod anti-affinity preset. Ignored if `secondary.affinity` is set. Allowed values: `soft` or `hard`\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAntiAffinityPreset: soft\n  ## Mariadb Secondary node affinity preset\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ##\n  nodeAffinityPreset:\n    ## @param secondary.nodeAffinityPreset.type MariaDB secondary node affinity preset type. Ignored if `secondary.affinity` is set. Allowed values: `soft` or `hard`\n    ##\n    type: \"\"\n    ## @param secondary.nodeAffinityPreset.key MariaDB secondary node label key to match Ignored if `secondary.affinity` is set.\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## @param secondary.nodeAffinityPreset.values MariaDB secondary node label values to match. Ignored if `secondary.affinity` is set.\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param secondary.affinity Affinity for MariaDB secondary pods assignment\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set\n  ##\n  affinity: {}\n  ## @param secondary.nodeSelector Node labels for MariaDB secondary pods assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param secondary.tolerations Tolerations for MariaDB secondary pods assignment\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param secondary.topologySpreadConstraints Topology Spread Constraints for MariaDB secondary pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## E.g.\n  ## topologySpreadConstraints:\n  ##   - maxSkew: 1\n  ##     topologyKey: topology.kubernetes.io/zone\n  ##     whenUnsatisfiable: DoNotSchedule\n  ##\n  topologySpreadConstraints: {}\n  ## @param secondary.priorityClassName Priority class for MariaDB secondary pods assignment\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n  ##\n  priorityClassName: \"\"\n  ## @param secondary.schedulerName Name of the k8s scheduler (other than default)\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  schedulerName: \"\"\n  ## @param secondary.podManagementPolicy podManagementPolicy to manage scaling operation of MariaDB secondary pods\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies\n  ##\n  podManagementPolicy: \"\"\n  ## MariaDB secondary Pod security context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param secondary.podSecurityContext.enabled Enable security context for MariaDB secondary pods\n  ## @param secondary.podSecurityContext.fsGroup Group ID for the mounted volumes' filesystem\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## MariaDB secondary container security context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param secondary.containerSecurityContext.enabled MariaDB secondary container securityContext\n  ## @param secondary.containerSecurityContext.runAsUser User ID for the MariaDB secondary container\n  ## @param secondary.containerSecurityContext.runAsNonRoot Set Controller container's Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## MariaDB secondary container's resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param secondary.resources.limits The resources limits for MariaDB secondary containers\n  ## @param secondary.resources.requests The requested resources for MariaDB secondary containers\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 100m\n    ##    memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 100m\n    ##    memory: 256Mi\n    requests: {}\n  ## Configure extra options for MariaDB Secondary containers' liveness, readiness and startup probes\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes)\n  ## @param secondary.startupProbe.enabled Enable startupProbe\n  ## @param secondary.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param secondary.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param secondary.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param secondary.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param secondary.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: false\n    initialDelaySeconds: 120\n    periodSeconds: 15\n    timeoutSeconds: 5\n    failureThreshold: 10\n    successThreshold: 1\n  ## Configure extra options for liveness probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param secondary.livenessProbe.enabled Enable livenessProbe\n  ## @param secondary.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param secondary.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param secondary.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param secondary.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param secondary.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 120\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 3\n    successThreshold: 1\n  ## @param secondary.readinessProbe.enabled Enable readinessProbe\n  ## @param secondary.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param secondary.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param secondary.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param secondary.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param secondary.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 3\n    successThreshold: 1\n  ## @param secondary.customStartupProbe Override default startup probe for MariaDB secondary containers\n  ##\n  customStartupProbe: {}\n  ## @param secondary.customLivenessProbe Override default liveness probe for MariaDB secondary containers\n  ##\n  customLivenessProbe: {}\n  ## @param secondary.customReadinessProbe Override default readiness probe for MariaDB secondary containers\n  ##\n  customReadinessProbe: {}\n  ## @param secondary.startupWaitOptions Override default builtin startup wait check options for MariaDB secondary containers\n  ## `bitnami/mariadb` Docker image has built-in startup check mechanism,\n  ## which periodically checks if MariaDB service has started up and stops it\n  ## if all checks have failed after X tries. Use these to control these checks.\n  ## ref: https://github.com/bitnami/bitnami-docker-mariadb/pull/240\n  ## Example (with default options):\n  ## startupWaitOptions:\n  ##   retries: 300\n  ##   waitTime: 2\n  ##\n  startupWaitOptions: {}\n  ## @param secondary.extraFlags MariaDB secondary additional command line flags\n  ## Can be used to specify command line flags, for example:\n  ## E.g.\n  ## extraFlags: \"--max-connect-errors=1000 --max_connections=155\"\n  ##\n  extraFlags: \"\"\n  ## @param secondary.extraEnvVars Extra environment variables to be set on MariaDB secondary containers\n  ## E.g.\n  ## extraEnvVars:\n  ##  - name: TZ\n  ##    value: \"Europe/Paris\"\n  ##\n  extraEnvVars: []\n  ## @param secondary.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for MariaDB secondary containers\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param secondary.extraEnvVarsSecret Name of existing Secret containing extra env vars for MariaDB secondary containers\n  ##\n  extraEnvVarsSecret: \"\"\n  ## Enable persistence using Persistent Volume Claims\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/\n  ##\n  persistence:\n    ## @param secondary.persistence.enabled Enable persistence on MariaDB secondary replicas using a `PersistentVolumeClaim`\n    ##\n    enabled: true\n    ## @param secondary.persistence.subPath Subdirectory of the volume to mount at\n    ##\n    subPath: \"\"\n    ## @param secondary.persistence.storageClass MariaDB secondary persistent volume storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    storageClass: \"\"\n    ## @param secondary.persistence.annotations MariaDB secondary persistent volume claim annotations\n    ##\n    annotations: {}\n    ## @param secondary.persistence.accessModes MariaDB secondary persistent volume access Modes\n    ##\n    accessModes:\n      - ReadWriteOnce\n    ## @param secondary.persistence.size MariaDB secondary persistent volume size\n    ##\n    size: 8Gi\n    ## @param secondary.persistence.selector Selector to match an existing Persistent Volume\n    ## selector:\n    ##   matchLabels:\n    ##     app: my-app\n    ##\n    selector: {}\n  ## @param secondary.extraVolumes Optionally specify extra list of additional volumes to the MariaDB secondary pod(s)\n  ##\n  extraVolumes: []\n  ## @param secondary.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the MariaDB secondary container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param secondary.initContainers Add additional init containers for the MariaDB secondary pod(s)\n  ##\n  initContainers: []\n  ## @param secondary.sidecars Add additional sidecar containers for the MariaDB secondary pod(s)\n  ##\n  sidecars: []\n  ## MariaDB Secondary Service parameters\n  ##\n  service:\n    ## @param secondary.service.type MariaDB secondary Kubernetes service type\n    ##\n    type: ClusterIP\n    ## @param secondary.service.ports.mysql MariaDB secondary Kubernetes service port\n    ##\n    ports:\n      mysql: 3306\n    ## @param secondary.service.nodePorts.mysql MariaDB secondary Kubernetes service node port\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n    ##\n    nodePorts:\n      mysql: \"\"\n    ## @param secondary.service.clusterIP MariaDB secondary Kubernetes service clusterIP IP\n    ## e.g:\n    ## clusterIP: None\n    ##\n    clusterIP: \"\"\n    ## @param secondary.service.loadBalancerIP MariaDB secondary loadBalancerIP if service type is `LoadBalancer`\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n    ##\n    loadBalancerIP: \"\"\n    ## @param secondary.service.externalTrafficPolicy Enable client source IP preservation\n    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n    ##\n    externalTrafficPolicy: Cluster\n    ## @param secondary.service.loadBalancerSourceRanges Address that are allowed when MariaDB secondary service is LoadBalancer\n    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n    ## E.g.\n    ## loadBalancerSourceRanges:\n    ##   - 10.10.10.0/24\n    ##\n    loadBalancerSourceRanges: []\n    ## @param secondary.service.extraPorts Extra ports to expose (normally used with the `sidecar` value)\n    ##\n    extraPorts: []\n    ## @param secondary.service.annotations Provide any additional annotations which may be required\n    ##\n    annotations: {}\n    ## @param secondary.service.sessionAffinity Session Affinity for Kubernetes service, can be \"None\" or \"ClientIP\"\n    ## If \"ClientIP\", consecutive client requests will be directed to the same Pod\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies\n    ##\n    sessionAffinity: None\n    ## @param secondary.service.sessionAffinityConfig Additional settings for the sessionAffinity\n    ## sessionAffinityConfig:\n    ##   clientIP:\n    ##     timeoutSeconds: 300\n    sessionAffinityConfig: {}\n  ## MariaDB secondary Pod Disruption Budget configuration\n  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  ##\n  pdb:\n    ## @param secondary.pdb.create Enable/disable a Pod Disruption Budget creation for MariaDB secondary pods\n    ##\n    create: false\n    ## @param secondary.pdb.minAvailable Minimum number/percentage of MariaDB secondary pods that should remain scheduled\n    ##\n    minAvailable: 1\n    ## @param secondary.pdb.maxUnavailable Maximum number/percentage of MariaDB secondary pods that may be made unavailable\n    ##\n    maxUnavailable: \"\"\n  ## @param secondary.revisionHistoryLimit Maximum number of revisions that will be maintained in the StatefulSet\n  ##\n  revisionHistoryLimit: 10\n\n## @section RBAC parameters\n\n## MariaDB pods ServiceAccount\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n##\nserviceAccount:\n  ## @param serviceAccount.create Enable the creation of a ServiceAccount for MariaDB pods\n  ##\n  create: true\n  ## @param serviceAccount.name Name of the created ServiceAccount\n  ## If not set and create is true, a name is generated using the mariadb.fullname template\n  ##\n  name: \"\"\n  ## @param serviceAccount.annotations Annotations for MariaDB Service Account\n  ##\n  annotations: {}\n  ## @param serviceAccount.automountServiceAccountToken Automount service account token for the server service account\n  ##\n  automountServiceAccountToken: false\n## Role Based Access\n## ref: https://kubernetes.io/docs/admin/authorization/rbac/\n##\nrbac:\n  ## @param rbac.create Whether to create and use RBAC resources or not\n  ##\n  create: false\n\n## @section Volume Permissions parameters\n\n## Init containers parameters:\n## volumePermissions: Change the owner and group of the persistent volume mountpoint to runAsUser:fsGroup values from the securityContext section.\n##\nvolumePermissions:\n  ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume(s) mountpoint to `runAsUser:fsGroup`\n  ##\n  enabled: false\n  ## @param volumePermissions.image.registry Init container volume-permissions image registry\n  ## @param volumePermissions.image.repository Init container volume-permissions image repository\n  ## @param volumePermissions.image.tag Init container volume-permissions image tag (immutable tags are recommended)\n  ## @param volumePermissions.image.pullPolicy Init container volume-permissions image pull policy\n  ## @param volumePermissions.image.pullSecrets Specify docker-registry secret names as an array\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/bitnami-shell\n    tag: 10-debian-10-r279\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## Example:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## @param volumePermissions.resources.limits Init container volume-permissions resource limits\n  ## @param volumePermissions.resources.requests Init container volume-permissions resource requests\n  ##\n  resources:\n    limits: {}\n    requests: {}\n\n## @section Metrics parameters\n\n## Mysqld Prometheus exporter parameters\n##\nmetrics:\n  ## @param metrics.enabled Start a side-car prometheus exporter\n  ##\n  enabled: false\n  ## @param metrics.image.registry Exporter image registry\n  ## @param metrics.image.repository Exporter image repository\n  ## @param metrics.image.tag Exporter image tag (immutable tags are recommended)\n  ## @param metrics.image.pullPolicy Exporter image pull policy\n  ## @param metrics.image.pullSecrets Specify docker-registry secret names as an array\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/mysqld-exporter\n    tag: 0.13.0-debian-10-r183\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## Example:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## @param metrics.annotations [object] Annotations for the Exporter pod\n  ##\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"9104\"\n  ## @param metrics.extraArgs [object] Extra args to be passed to mysqld_exporter\n  ## ref: https://github.com/prometheus/mysqld_exporter/\n  ## E.g.\n  ## - --collect.auto_increment.columns\n  ## - --collect.binlog_size\n  ## - --collect.engine_innodb_status\n  ## - --collect.engine_tokudb_status\n  ## - --collect.global_status\n  ## - --collect.global_variables\n  ## - --collect.info_schema.clientstats\n  ## - --collect.info_schema.innodb_metrics\n  ## - --collect.info_schema.innodb_tablespaces\n  ## - --collect.info_schema.innodb_cmp\n  ## - --collect.info_schema.innodb_cmpmem\n  ## - --collect.info_schema.processlist\n  ## - --collect.info_schema.processlist.min_time\n  ## - --collect.info_schema.query_response_time\n  ## - --collect.info_schema.tables\n  ## - --collect.info_schema.tables.databases\n  ## - --collect.info_schema.tablestats\n  ## - --collect.info_schema.userstats\n  ## - --collect.perf_schema.eventsstatements\n  ## - --collect.perf_schema.eventsstatements.digest_text_limit\n  ## - --collect.perf_schema.eventsstatements.limit\n  ## - --collect.perf_schema.eventsstatements.timelimit\n  ## - --collect.perf_schema.eventswaits\n  ## - --collect.perf_schema.file_events\n  ## - --collect.perf_schema.file_instances\n  ## - --collect.perf_schema.indexiowaits\n  ## - --collect.perf_schema.tableiowaits\n  ## - --collect.perf_schema.tablelocks\n  ## - --collect.perf_schema.replication_group_member_stats\n  ## - --collect.slave_status\n  ## - --collect.slave_hosts\n  ## - --collect.heartbeat\n  ## - --collect.heartbeat.database\n  ## - --collect.heartbeat.table\n  ##\n  extraArgs:\n    primary: []\n    secondary: []\n  ## MariaDB metrics container Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param metrics.containerSecurityContext.enabled Enable security context for MariaDB metrics container\n  ## Example:\n  ##   containerSecurityContext:\n  ##     enabled: true\n  ##     capabilities:\n  ##       drop: [\"NET_RAW\"]\n  ##     readOnlyRootFilesystem: true\n  ##\n  containerSecurityContext:\n    enabled: false\n  ## Mysqld Prometheus exporter resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param metrics.resources.limits The resources limits for MariaDB prometheus exporter containers\n  ## @param metrics.resources.requests The requested resources for MariaDB prometheus exporter containers\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 100m\n    ##    memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 100m\n    ##    memory: 256Mi\n    requests: {}\n  ## Configure extra options for liveness probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param metrics.livenessProbe.enabled Enable livenessProbe\n  ## @param metrics.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param metrics.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param metrics.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param metrics.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param metrics.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 120\n    periodSeconds: 10\n    timeoutSeconds: 1\n    successThreshold: 1\n    failureThreshold: 3\n  ## Configure extra options for readiness probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param metrics.readinessProbe.enabled Enable readinessProbe\n  ## @param metrics.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param metrics.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param metrics.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param metrics.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param metrics.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 1\n    successThreshold: 1\n    failureThreshold: 3\n  ## Prometheus Service Monitor\n  ## ref: https://github.com/coreos/prometheus-operator\n  ##\n  serviceMonitor:\n    ## @param metrics.serviceMonitor.enabled Create ServiceMonitor Resource for scraping metrics using PrometheusOperator\n    ##\n    enabled: false\n    ## @param metrics.serviceMonitor.namespace Namespace which Prometheus is running in\n    ##\n    namespace: \"\"\n    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in prometheus.\n    ##\n    jobLabel: \"\"\n    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped\n    ##\n    interval: 30s\n    ## @param metrics.serviceMonitor.scrapeTimeout Specify the timeout after which the scrape is ended\n    ## e.g:\n    ## scrapeTimeout: 30s\n    ##\n    scrapeTimeout: \"\"\n    ## @param metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig\n    ##\n    relabelings: []\n    ## @param metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before ingestion\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig\n    ##\n    metricRelabelings: []\n    ## @param metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels\n    ##\n    honorLabels: false\n    ## @param metrics.serviceMonitor.selector ServiceMonitor selector labels\n    ## ref: https://github.com/bitnami/charts/tree/master/bitnami/prometheus-operator#prometheus-configuration\n    ##\n    ## selector:\n    ##   prometheus: my-prometheus\n    ##\n    selector: {}\n    ## @param metrics.serviceMonitor.labels Extra labels for the ServiceMonitor\n    ##\n    labels: {}\n\n## @section NetworkPolicy parameters\n\n## Add networkpolicies\n##\nnetworkPolicy:\n  ## @param networkPolicy.enabled Enable network policies\n  ##\n  enabled: false\n  ## @param networkPolicy.metrics.enabled Enable network policy for metrics (prometheus)\n  ## @param networkPolicy.metrics.namespaceSelector [object] Monitoring namespace selector labels. These labels will be used to identify the prometheus' namespace.\n  ## @param networkPolicy.metrics.podSelector [object] Monitoring pod selector labels. These labels will be used to identify the Prometheus pods.\n  ##\n  metrics:\n    enabled: false\n    ## e.g:\n    ## podSelector:\n    ##   label: monitoring\n    ##\n    podSelector: {}\n    ## e.g:\n    ## namespaceSelector:\n    ##   label: monitoring\n    ##\n    namespaceSelector: {}\n  ## @param networkPolicy.ingressRules.primaryAccessOnlyFrom.enabled Enable ingress rule that makes primary mariadb nodes only accessible from a particular origin.\n  ## @param networkPolicy.ingressRules.primaryAccessOnlyFrom.namespaceSelector [object] Namespace selector label that is allowed to access the primary node. This label will be used to identified the allowed namespace(s).\n  ## @param networkPolicy.ingressRules.primaryAccessOnlyFrom.podSelector [object] Pods selector label that is allowed to access the primary node. This label will be used to identified the allowed pod(s).\n  ## @param networkPolicy.ingressRules.primaryAccessOnlyFrom.customRules [object] Custom network policy for the primary node.\n  ## @param networkPolicy.ingressRules.secondaryAccessOnlyFrom.enabled Enable ingress rule that makes primary mariadb nodes only accessible from a particular origin.\n  ## @param networkPolicy.ingressRules.secondaryAccessOnlyFrom.namespaceSelector [object] Namespace selector label that is allowed to acces the secondary nodes. This label will be used to identified the allowed namespace(s).\n  ## @param networkPolicy.ingressRules.secondaryAccessOnlyFrom.podSelector [object] Pods selector label that is allowed to access the secondary nodes. This label will be used to identified the allowed pod(s).\n  ## @param networkPolicy.ingressRules.secondaryAccessOnlyFrom.customRules [object] Custom network policy for the secondary nodes.\n  ##\n  ingressRules:\n    ## Allow access to the primary node only from the indicated:\n    primaryAccessOnlyFrom:\n      enabled: false\n      ## e.g:\n      ## namespaceSelector:\n      ##   label: ingress\n      ##\n      namespaceSelector: {}\n      ## e.g:\n      ## podSelector:\n      ##   label: access\n      ##\n      podSelector: {}\n      ## custom ingress rules\n      ## e.g:\n      ## customRules:\n      ##   - from:\n      ##       - namespaceSelector:\n      ##           matchLabels:\n      ##             label: example\n      customRules: {}\n\n    ## Allow access to the secondary node only from the indicated:\n    secondaryAccessOnlyFrom:\n      enabled: false\n      ## e.g:\n      ## namespaceSelector:\n      ##   label: ingress\n      ##\n      namespaceSelector: {}\n      ## e.g:\n      ## podSelector:\n      ##   label: access\n      ##\n      podSelector: {}\n      ## custom ingress rules\n      ## e.g:\n      ## CustomRules:\n      ##   - from:\n      ##       - namespaceSelector:\n      ##           matchLabels:\n      ##             label: example\n      customRules: {}\n\n  ## @param networkPolicy.egressRules.denyConnectionsToExternal Enable egress rule that denies outgoing traffic outside the cluster, except for DNS (port 53).\n  ## @param networkPolicy.egressRules.customRules [object] Custom network policy rule\n  ##\n  egressRules:\n    # Deny connections to external. This is not compatible with an external database.\n    denyConnectionsToExternal: false\n    ## Additional custom egress rules\n    ## e.g:\n    ## customRules:\n    ##   - to:\n    ##       - namespaceSelector:\n    ##           matchLabels:\n    ##             label: example\n    customRules: {}\n"
            ],
            "verify": false,
            "version": "10.1.1",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub",
            "module.kube.kubernetes_namespace.keycloak",
            "module.kube.kubernetes_namespace.ldap",
            "module.kube.kubernetes_namespace.mariadb",
            "module.kube.kubernetes_namespace.mlflow"
          ]
        }
      ]
    },
    {
      "module": "module.mlflow_install",
      "mode": "managed",
      "type": "kubernetes_deployment",
      "name": "mlflow_server",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "mlflow/mlflow-server",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 5,
                "labels": {
                  "app": "mlflow-server"
                },
                "name": "mlflow-server",
                "namespace": "mlflow",
                "resource_version": "88192",
                "uid": "a1d37d91-b2cc-44b5-90fa-c5669a4f21d8"
              }
            ],
            "spec": [
              {
                "min_ready_seconds": 0,
                "paused": false,
                "progress_deadline_seconds": 600,
                "replicas": "1",
                "revision_history_limit": 10,
                "selector": [
                  {
                    "match_expressions": [],
                    "match_labels": {
                      "app": "mlflow-server"
                    }
                  }
                ],
                "strategy": [
                  {
                    "rolling_update": [
                      {
                        "max_surge": "25%",
                        "max_unavailable": "25%"
                      }
                    ],
                    "type": "RollingUpdate"
                  }
                ],
                "template": [
                  {
                    "metadata": [
                      {
                        "annotations": {},
                        "generate_name": "",
                        "generation": 0,
                        "labels": {
                          "app": "mlflow-server"
                        },
                        "name": "",
                        "namespace": "",
                        "resource_version": "",
                        "uid": ""
                      }
                    ],
                    "spec": [
                      {
                        "active_deadline_seconds": 0,
                        "affinity": [],
                        "automount_service_account_token": true,
                        "container": [
                          {
                            "args": [],
                            "command": [
                              "/bin/bash",
                              "-c",
                              "mlflow server --host 0.0.0.0 --backend-store-uri ${BACKEND_URI} --default-artifact-root ${DEFAULT_ARTIFACT_ROOT}"
                            ],
                            "env": [
                              {
                                "name": "MLFLOW_S3_ENDPOINT_URL",
                                "value": "http://submarine-minio-service:9000",
                                "value_from": []
                              },
                              {
                                "name": "AWS_ACCESS_KEY_ID",
                                "value": "submarine_minio",
                                "value_from": []
                              },
                              {
                                "name": "AWS_SECRET_ACCESS_KEY",
                                "value": "submarine_minio",
                                "value_from": []
                              },
                              {
                                "name": "BACKEND_URI",
                                "value": "mysql+pymysql://root:admin@mariadb.mariadb.svc.cluster.local:3306/mlflow_db",
                                "value_from": []
                              },
                              {
                                "name": "DEFAULT_ARTIFACT_ROOT",
                                "value": "s3://mlflow",
                                "value_from": []
                              }
                            ],
                            "env_from": [],
                            "image": "apache/submarine:mlflow-0.6.0",
                            "image_pull_policy": "Always",
                            "lifecycle": [],
                            "liveness_probe": [],
                            "name": "server",
                            "port": [
                              {
                                "container_port": 5000,
                                "host_ip": "",
                                "host_port": 0,
                                "name": "",
                                "protocol": "TCP"
                              }
                            ],
                            "readiness_probe": [],
                            "resources": [
                              {
                                "limits": null,
                                "requests": null
                              }
                            ],
                            "security_context": [],
                            "startup_probe": [],
                            "stdin": false,
                            "stdin_once": false,
                            "termination_message_path": "/dev/termination-log",
                            "termination_message_policy": "File",
                            "tty": false,
                            "volume_mount": [],
                            "working_dir": ""
                          }
                        ],
                        "dns_config": [],
                        "dns_policy": "ClusterFirst",
                        "enable_service_links": true,
                        "host_aliases": [],
                        "host_ipc": false,
                        "host_network": false,
                        "host_pid": false,
                        "hostname": "",
                        "image_pull_secrets": [],
                        "init_container": [],
                        "node_name": "",
                        "node_selector": {},
                        "priority_class_name": "",
                        "readiness_gate": [],
                        "restart_policy": "Always",
                        "security_context": [],
                        "service_account_name": "",
                        "share_process_namespace": false,
                        "subdomain": "",
                        "termination_grace_period_seconds": 30,
                        "toleration": [],
                        "topology_spread_constraint": [],
                        "volume": []
                      }
                    ]
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_rollout": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6NjAwMDAwMDAwMDAwLCJ1cGRhdGUiOjYwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9",
          "dependencies": [
            "module.kube.kubernetes_namespace.ldap",
            "module.kube.kubernetes_namespace.mariadb",
            "module.kube.kubernetes_namespace.mlflow",
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub",
            "module.kube.kubernetes_namespace.keycloak"
          ]
        }
      ]
    },
    {
      "module": "module.mlflow_install",
      "mode": "managed",
      "type": "kubernetes_service",
      "name": "mlflow_server",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "mlflow/mlflow-server",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {
                  "app": "mlflow-server"
                },
                "name": "mlflow-server",
                "namespace": "mlflow",
                "resource_version": "81059",
                "uid": "2e453bc4-18d2-425f-98cf-51df5061e025"
              }
            ],
            "spec": [
              {
                "cluster_ip": "10.43.238.9",
                "external_ips": [],
                "external_name": "",
                "external_traffic_policy": "",
                "health_check_node_port": 0,
                "load_balancer_ip": "",
                "load_balancer_source_ranges": [],
                "port": [
                  {
                    "name": "http",
                    "node_port": 0,
                    "port": 5000,
                    "protocol": "TCP",
                    "target_port": "5000"
                  }
                ],
                "publish_not_ready_addresses": false,
                "selector": {
                  "app": "mlflow-server"
                },
                "session_affinity": "None",
                "type": "ClusterIP"
              }
            ],
            "status": [
              {
                "load_balancer": [
                  {
                    "ingress": []
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_load_balancer": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "module.kube.kubernetes_namespace.mlflow",
            "module.kube.kubernetes_namespace.istio_system",
            "module.kube.kubernetes_namespace.jupyterhub",
            "module.kube.kubernetes_namespace.keycloak",
            "module.kube.kubernetes_namespace.ldap",
            "module.kube.kubernetes_namespace.mariadb"
          ]
        }
      ]
    }
  ]
}
